{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e706acf-4c63-4bbf-9751-9037ad26af16",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cd397a-3169-4956-8b4b-298e01b2f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f12f546c-29c4-4008-a8f1-69516627c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv(\"loan_update.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719d694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking for missing values\n",
    "# function to show percentage of null values-\n",
    "def null_values(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9bcb8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has 34 columns.\n",
      "There are 8 columns that have missing values.\n",
      "                      Missing Values  % of Total Values\n",
      "emp_title                      85791                6.4\n",
      "emp_length                     78516                5.8\n",
      "mort_acc                       47281                3.5\n",
      "title                          16660                1.2\n",
      "revol_util                       857                0.1\n",
      "pub_rec_bankruptcies             697                0.1\n",
      "dti                              374                0.0\n",
      "zip_code                           1                0.0\n"
     ]
    }
   ],
   "source": [
    "null_df = null_values(loan_data)\n",
    "print(null_df)\n",
    "del null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45143678-2e82-461c-a4d7-050371b173b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_impute(df,feature) :\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    df[feature] = median_imputer.fit_transform(df[feature].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0c4925-76f1-4604-beb1-7894ae7b1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_impute(loan_data,[\"pub_rec_bankruptcies\"])\n",
    "median_impute(loan_data,['revol_util'])\n",
    "median_impute(loan_data,['dti'])\n",
    "median_impute(loan_data,['mort_acc'])\n",
    "median_impute(loan_data,['emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957a0707-8e50-4aa7-b44a-3b4a4d1d2647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has 34 columns.\n",
      "There are 3 columns that have missing values.\n",
      "           Missing Values  % of Total Values\n",
      "emp_title           85791                6.4\n",
      "title               16660                1.2\n",
      "zip_code                1                0.0\n"
     ]
    }
   ],
   "source": [
    "### checking if null values are filled\n",
    "null_df = null_values(loan_data)\n",
    "print(null_df)\n",
    "del null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3246e6ae-a1b4-4ae8-ac47-0fde468c96b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>Fico_average</th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68407277</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>123.03</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>leadman</td>\n",
       "      <td>10.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>190xx</td>\n",
       "      <td>PA</td>\n",
       "      <td>5.91</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>NorthEast</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68355089</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>820.28</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>small_business</td>\n",
       "      <td>Business</td>\n",
       "      <td>577xx</td>\n",
       "      <td>SD</td>\n",
       "      <td>16.06</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21470.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>MidWest</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68341763</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.78</td>\n",
       "      <td>432.66</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>truck driver</td>\n",
       "      <td>10.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605xx</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.78</td>\n",
       "      <td>2000-08-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7869.0</td>\n",
       "      <td>56.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>w</td>\n",
       "      <td>Joint App</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>MidWest</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68476807</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.45</td>\n",
       "      <td>289.91</td>\n",
       "      <td>F</td>\n",
       "      <td>F1</td>\n",
       "      <td>Contract Specialist</td>\n",
       "      <td>3.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>Major purchase</td>\n",
       "      <td>174xx</td>\n",
       "      <td>PA</td>\n",
       "      <td>25.37</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21929.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>NorthEast</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68426831</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>405.18</td>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>Veterinary Tecnician</td>\n",
       "      <td>4.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>300xx</td>\n",
       "      <td>GA</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1987-10-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SouthEast</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt  funded_amnt_inv  funded_amnt  term  int_rate  \\\n",
       "id                                                                  \n",
       "68407277     3600.0           3600.0       3600.0     0     13.99   \n",
       "68355089    24700.0          24700.0      24700.0     0     11.99   \n",
       "68341763    20000.0          20000.0      20000.0     1     10.78   \n",
       "68476807    10400.0          10400.0      10400.0     1     22.45   \n",
       "68426831    11950.0          11950.0      11950.0     0     13.44   \n",
       "\n",
       "          installment grade sub_grade             emp_title  emp_length  \\\n",
       "id                                                                        \n",
       "68407277       123.03     C        C4               leadman        10.0   \n",
       "68355089       820.28     C        C1              Engineer        10.0   \n",
       "68341763       432.66     B        B4          truck driver        10.0   \n",
       "68476807       289.91     F        F1   Contract Specialist         3.0   \n",
       "68426831       405.18     C        C3  Veterinary Tecnician         4.0   \n",
       "\n",
       "          fico_range_high  fico_range_low home_ownership  annual_inc  \\\n",
       "id                                                                     \n",
       "68407277            679.0           675.0       MORTGAGE     55000.0   \n",
       "68355089            719.0           715.0       MORTGAGE     65000.0   \n",
       "68341763            699.0           695.0       MORTGAGE     63000.0   \n",
       "68476807            699.0           695.0       MORTGAGE    104433.0   \n",
       "68426831            694.0           690.0           RENT     34000.0   \n",
       "\n",
       "         verification_status   issue_d  loan_status             purpose  \\\n",
       "id                                                                        \n",
       "68407277        Not Verified  Dec-2015            1  debt_consolidation   \n",
       "68355089        Not Verified  Dec-2015            1      small_business   \n",
       "68341763        Not Verified  Dec-2015            1    home_improvement   \n",
       "68476807     Source Verified  Dec-2015            1      major_purchase   \n",
       "68426831     Source Verified  Dec-2015            1  debt_consolidation   \n",
       "\n",
       "                       title zip_code addr_state    dti earliest_cr_line  \\\n",
       "id                                                                         \n",
       "68407277  Debt consolidation    190xx         PA   5.91       2003-08-01   \n",
       "68355089            Business    577xx         SD  16.06       1999-12-01   \n",
       "68341763                 NaN    605xx         IL  10.78       2000-08-01   \n",
       "68476807      Major purchase    174xx         PA  25.37       1998-06-01   \n",
       "68426831  Debt consolidation    300xx         GA  10.20       1987-10-01   \n",
       "\n",
       "          open_acc  revol_bal  revol_util  total_acc initial_list_status  \\\n",
       "id                                                                         \n",
       "68407277       7.0     2765.0        29.7       13.0                   w   \n",
       "68355089      22.0    21470.0        19.2       38.0                   w   \n",
       "68341763       6.0     7869.0        56.2       18.0                   w   \n",
       "68476807      12.0    21929.0        64.5       35.0                   w   \n",
       "68426831       5.0     8822.0        68.4        6.0                   w   \n",
       "\n",
       "         application_type  mort_acc  pub_rec_bankruptcies  Fico_average  \\\n",
       "id                                                                        \n",
       "68407277       Individual       1.0                   0.0         677.0   \n",
       "68355089       Individual       1.0                   0.0         717.0   \n",
       "68341763        Joint App       1.0                   0.0         697.0   \n",
       "68476807       Individual       1.0                   0.0         697.0   \n",
       "68426831       Individual       0.0                   0.0         692.0   \n",
       "\n",
       "             region  year  \n",
       "id                         \n",
       "68407277  NorthEast  2003  \n",
       "68355089    MidWest  1999  \n",
       "68341763    MidWest  2000  \n",
       "68476807  NorthEast  1998  \n",
       "68426831  SouthEast  1987  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ed3875-91fa-40e4-8dbc-502d9a5a6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1345350 entries, 68407277 to 88224441\n",
      "Data columns (total 34 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   loan_amnt             1345350 non-null  float64\n",
      " 1   funded_amnt_inv       1345350 non-null  float64\n",
      " 2   funded_amnt           1345350 non-null  float64\n",
      " 3   term                  1345350 non-null  int64  \n",
      " 4   int_rate              1345350 non-null  float64\n",
      " 5   installment           1345350 non-null  float64\n",
      " 6   grade                 1345350 non-null  object \n",
      " 7   sub_grade             1345350 non-null  object \n",
      " 8   emp_title             1259559 non-null  object \n",
      " 9   emp_length            1345350 non-null  float64\n",
      " 10  fico_range_high       1345350 non-null  float64\n",
      " 11  fico_range_low        1345350 non-null  float64\n",
      " 12  home_ownership        1345350 non-null  object \n",
      " 13  annual_inc            1345350 non-null  float64\n",
      " 14  verification_status   1345350 non-null  object \n",
      " 15  issue_d               1345350 non-null  object \n",
      " 16  loan_status           1345350 non-null  int64  \n",
      " 17  purpose               1345350 non-null  object \n",
      " 18  title                 1328690 non-null  object \n",
      " 19  zip_code              1345349 non-null  object \n",
      " 20  addr_state            1345350 non-null  object \n",
      " 21  dti                   1345350 non-null  float64\n",
      " 22  earliest_cr_line      1345350 non-null  object \n",
      " 23  open_acc              1345350 non-null  float64\n",
      " 24  revol_bal             1345350 non-null  float64\n",
      " 25  revol_util            1345350 non-null  float64\n",
      " 26  total_acc             1345350 non-null  float64\n",
      " 27  initial_list_status   1345350 non-null  object \n",
      " 28  application_type      1345350 non-null  object \n",
      " 29  mort_acc              1345350 non-null  float64\n",
      " 30  pub_rec_bankruptcies  1345350 non-null  float64\n",
      " 31  Fico_average          1345350 non-null  float64\n",
      " 32  region                1345350 non-null  object \n",
      " 33  year                  1345350 non-null  int64  \n",
      "dtypes: float64(17), int64(3), object(14)\n",
      "memory usage: 359.2+ MB\n"
     ]
    }
   ],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d389015-8a38-4874-b230-b11f8f6db61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1345350 entries, 68407277 to 88224441\n",
      "Data columns (total 34 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   loan_amnt             1345350 non-null  float64\n",
      " 1   funded_amnt_inv       1345350 non-null  float64\n",
      " 2   funded_amnt           1345350 non-null  float64\n",
      " 3   term                  1345350 non-null  int64  \n",
      " 4   int_rate              1345350 non-null  float64\n",
      " 5   installment           1345350 non-null  float64\n",
      " 6   grade                 1345350 non-null  object \n",
      " 7   sub_grade             1345350 non-null  object \n",
      " 8   emp_title             1259559 non-null  object \n",
      " 9   emp_length            1345350 non-null  float64\n",
      " 10  fico_range_high       1345350 non-null  float64\n",
      " 11  fico_range_low        1345350 non-null  float64\n",
      " 12  home_ownership        1345350 non-null  object \n",
      " 13  annual_inc            1345350 non-null  float64\n",
      " 14  verification_status   1345350 non-null  object \n",
      " 15  issue_d               1345350 non-null  object \n",
      " 16  loan_status           1345350 non-null  int64  \n",
      " 17  purpose               1345350 non-null  object \n",
      " 18  title                 1328690 non-null  object \n",
      " 19  zip_code              1345349 non-null  object \n",
      " 20  addr_state            1345350 non-null  object \n",
      " 21  dti                   1345350 non-null  float64\n",
      " 22  earliest_cr_line      1345350 non-null  object \n",
      " 23  open_acc              1345350 non-null  float64\n",
      " 24  revol_bal             1345350 non-null  float64\n",
      " 25  revol_util            1345350 non-null  float64\n",
      " 26  total_acc             1345350 non-null  float64\n",
      " 27  initial_list_status   1345350 non-null  object \n",
      " 28  application_type      1345350 non-null  object \n",
      " 29  mort_acc              1345350 non-null  float64\n",
      " 30  pub_rec_bankruptcies  1345350 non-null  float64\n",
      " 31  Fico_average          1345350 non-null  float64\n",
      " 32  region                1345350 non-null  object \n",
      " 33  year                  1345350 non-null  int64  \n",
      "dtypes: float64(17), int64(3), object(14)\n",
      "memory usage: 359.2+ MB\n"
     ]
    }
   ],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6e5bfc-f0ee-46a0-af0b-60beb621ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outlier_Drop_and_Skewness_handler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        if features is None:\n",
    "            features = ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'open_acc',\n",
    "                        'revol_bal', 'revol_util', 'total_acc', 'Fico_average', 'mort_acc']\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            df = X.copy()\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            df = pd.DataFrame(X, columns=self.features)\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a DataFrame or NumPy array.\")\n",
    "\n",
    "        not_present = [feat for feat in self.features if feat not in df.columns]\n",
    "        if not_present:\n",
    "            print(f\"The following features are not in the dataframe: {not_present}\")\n",
    "\n",
    "        #for feat in self.features:\n",
    "            #if df[feat].dtype.kind in 'bifc' and (df[feat] > 0).all():\n",
    "                #df[feat] = np.log(df[feat] + 1)\n",
    "\n",
    "        Q1 = df[self.features].quantile(0.25)\n",
    "        Q3 = df[self.features].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[~((df[self.features] < (Q1 - 3 * IQR)) | (df[self.features] > (Q3 + 3 * IQR))).any(axis=1)]\n",
    "\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d3067f-cb41-4dc9-90fb-85dbe077fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class features_to_drop(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, feature=None):\n",
    "        if feature is None:\n",
    "            feature = ['funded_amnt_inv','funded_amnt','grade','emp_title',\n",
    "                       'fico_range_high','fico_range_low','issue_d',\n",
    "                       'title','addr_state','zip_code','earliest_cr_line']\n",
    "        self.feature = feature\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        not_present = [feat for feat in self.feature if feat not in df.columns]\n",
    "        if not_present:\n",
    "            print(f\"The following features are not in the dataframe: {not_present}\")\n",
    "        present_features = [feat for feat in self.feature if feat in df.columns]\n",
    "        if present_features:\n",
    "            df = df.drop(present_features, axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be325f6-6d6f-4807-b295-27d38b9d217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_hot_encoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,feature = ['term','home_ownership','verification_status',\n",
    "                                 'purpose','initial_list_status',\n",
    "                                 'application_type','region']):\n",
    "        self.feature = feature                         \n",
    "    def fit(self,df):\n",
    "        return self\n",
    "    def transform(self,df):\n",
    "        if (set(self.feature).issubset(df.columns)):\n",
    "            df = pd.get_dummies(df, columns = self.feature)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df\n",
    "######\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "class FeatureHashing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=10, feature=['home_ownership', 'verification_status', 'purpose', 'initial_list_status', 'application_type', 'region']):\n",
    "        self.feature = feature\n",
    "        self.hasher = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        not_present = [feat for feat in self.feature if feat not in df.columns]\n",
    "        if not_present:\n",
    "            print(f\"The following features are not in the dataframe: {not_present}\")\n",
    "        present_features = [feat for feat in self.feature if feat in df.columns]\n",
    "        for feat in present_features:\n",
    "            hashed_features = self.hasher.transform(df[feat].apply(lambda x: [x]).tolist())\n",
    "            hashed_features = pd.DataFrame(hashed_features.toarray(), columns=[f\"{feat}_hashed_{i}\" for i in range(self.hasher.n_features)], index=df.index)\n",
    "            df = pd.concat([df, hashed_features], axis=1)\n",
    "            df = df.drop(feat, axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49905787-eba7-4ce8-af5b-cfe53b1ad527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalFeatNames(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature=['sub_grade']):\n",
    "        self.feature = feature\n",
    "        self.ordinal_enc = OrdinalEncoder()\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        if (set(self.feature).issubset(df.columns)):\n",
    "            self.ordinal_enc.fit(df[self.feature])\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if (set(self.feature).issubset(df.columns)):\n",
    "            df[self.feature] = self.ordinal_enc.transform(df[self.feature])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5886db6-01ec-4a95-85fe-ae63ead1871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class MinMaxWithFeatNames(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature=['loan_amnt','int_rate','installment','emp_length','annual_inc','dti',\n",
    "                                'open_acc','revol_bal','revol_util','total_acc', 'mort_acc',\n",
    "                                'pub_rec_bankruptcies','Fico_average']):\n",
    "        self.feature = feature\n",
    "        self.min_max_enc = MinMaxScaler()\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        if (set(self.feature).issubset(df.columns)):\n",
    "            self.min_max_enc.fit(df[self.feature])\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if (set(self.feature).issubset(df.columns)):\n",
    "            df[self.feature] = self.min_max_enc.transform(df[self.feature])\n",
    "            return df\n",
    "        else:\n",
    "            print(\"One or more features are not in the dataframe\")\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0237a46a-a639-418a-b9f4-5c8086fd9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Oversample(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if 'loan_status' not in df.columns:\n",
    "            raise ValueError(\"loan_status is not in the dataframe\")\n",
    "\n",
    "        # Separate the input features (X) and the target variable (y)\n",
    "        X = df.loc[:, df.columns != 'loan_status']\n",
    "        y = df['loan_status']\n",
    "\n",
    "        # SMOTE function to oversample the minority class to fix the imbalanced data\n",
    "        oversample = SMOTE(sampling_strategy='minority')\n",
    "        X_bal, y_bal = oversample.fit_resample(X, y)\n",
    "\n",
    "        # Concatenate the balanced X and y into a new dataframe\n",
    "        df_bal = pd.concat([pd.DataFrame(X_bal, columns=X.columns), pd.DataFrame(y_bal, columns=['loan_status'])], axis=1)\n",
    "\n",
    "        return df_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504d9247-02d0-4a61-b3e5-c0cc184edf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split loan_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_df,Test_df = train_test_split(loan_data,stratify=loan_data[\"loan_status\"], test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3efca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_target(df, target_column):\n",
    "    \"\"\"\n",
    "    Separates the features and target from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to separate.\n",
    "    target_column (str): The name of the target column in df.\n",
    "\n",
    "    Returns:\n",
    "    X (pd.DataFrame): The features.\n",
    "    y (pd.Series): The target.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column].values.reshape(-1, 1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b59b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076280, 34)\n",
      "(269070, 34)\n"
     ]
    }
   ],
   "source": [
    "print (Train_df.shape)\n",
    "print (Test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d5c5e77-7f07-41fc-b7b0-1b94d66c8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create the final pipeline with preprocessing and oversampling\n",
    "pipeline = ImbPipeline([\n",
    "    ('outlier_skewness', Outlier_Drop_and_Skewness_handler()),\n",
    "    ('drop_feature', features_to_drop()),\n",
    "    ('one_hot_encoding', FeatureHashing()),\n",
    "    ('ordinal_encoding', OrdinalFeatNames()),\n",
    "    ('standardize', MinMaxWithFeatNames()),\n",
    "    ('smote', Oversample())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# fit and transform the training data\n",
    "Train_df = pipeline.fit_transform(Train_df)\n",
    "\n",
    "# transform the testing data (without oversampling)\n",
    "Test_df = pipeline[1:-1].transform(Test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64933817-87a8-4fc0-a115-f451675beabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>Fico_average</th>\n",
       "      <th>year</th>\n",
       "      <th>home_ownership_hashed_0</th>\n",
       "      <th>home_ownership_hashed_1</th>\n",
       "      <th>home_ownership_hashed_2</th>\n",
       "      <th>home_ownership_hashed_3</th>\n",
       "      <th>home_ownership_hashed_4</th>\n",
       "      <th>home_ownership_hashed_5</th>\n",
       "      <th>home_ownership_hashed_6</th>\n",
       "      <th>home_ownership_hashed_7</th>\n",
       "      <th>home_ownership_hashed_8</th>\n",
       "      <th>home_ownership_hashed_9</th>\n",
       "      <th>verification_status_hashed_0</th>\n",
       "      <th>verification_status_hashed_1</th>\n",
       "      <th>verification_status_hashed_2</th>\n",
       "      <th>verification_status_hashed_3</th>\n",
       "      <th>verification_status_hashed_4</th>\n",
       "      <th>verification_status_hashed_5</th>\n",
       "      <th>verification_status_hashed_6</th>\n",
       "      <th>verification_status_hashed_7</th>\n",
       "      <th>verification_status_hashed_8</th>\n",
       "      <th>verification_status_hashed_9</th>\n",
       "      <th>purpose_hashed_0</th>\n",
       "      <th>purpose_hashed_1</th>\n",
       "      <th>purpose_hashed_2</th>\n",
       "      <th>purpose_hashed_3</th>\n",
       "      <th>purpose_hashed_4</th>\n",
       "      <th>purpose_hashed_5</th>\n",
       "      <th>purpose_hashed_6</th>\n",
       "      <th>purpose_hashed_7</th>\n",
       "      <th>purpose_hashed_8</th>\n",
       "      <th>purpose_hashed_9</th>\n",
       "      <th>initial_list_status_hashed_0</th>\n",
       "      <th>initial_list_status_hashed_1</th>\n",
       "      <th>initial_list_status_hashed_2</th>\n",
       "      <th>initial_list_status_hashed_3</th>\n",
       "      <th>initial_list_status_hashed_4</th>\n",
       "      <th>initial_list_status_hashed_5</th>\n",
       "      <th>initial_list_status_hashed_6</th>\n",
       "      <th>initial_list_status_hashed_7</th>\n",
       "      <th>initial_list_status_hashed_8</th>\n",
       "      <th>initial_list_status_hashed_9</th>\n",
       "      <th>application_type_hashed_0</th>\n",
       "      <th>application_type_hashed_1</th>\n",
       "      <th>application_type_hashed_2</th>\n",
       "      <th>application_type_hashed_3</th>\n",
       "      <th>application_type_hashed_4</th>\n",
       "      <th>application_type_hashed_5</th>\n",
       "      <th>application_type_hashed_6</th>\n",
       "      <th>application_type_hashed_7</th>\n",
       "      <th>application_type_hashed_8</th>\n",
       "      <th>application_type_hashed_9</th>\n",
       "      <th>region_hashed_0</th>\n",
       "      <th>region_hashed_1</th>\n",
       "      <th>region_hashed_2</th>\n",
       "      <th>region_hashed_3</th>\n",
       "      <th>region_hashed_4</th>\n",
       "      <th>region_hashed_5</th>\n",
       "      <th>region_hashed_6</th>\n",
       "      <th>region_hashed_7</th>\n",
       "      <th>region_hashed_8</th>\n",
       "      <th>region_hashed_9</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.128118</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.186581</td>\n",
       "      <td>0.309085</td>\n",
       "      <td>0.56250</td>\n",
       "      <td>0.412459</td>\n",
       "      <td>0.222407</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113924</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.104540</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.233788</td>\n",
       "      <td>0.292919</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>0.149750</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119938</td>\n",
       "      <td>0.299083</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.292235</td>\n",
       "      <td>0.453767</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>0.221852</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.240506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318536</td>\n",
       "      <td>0.213773</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305722</td>\n",
       "      <td>0.566440</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.441571</td>\n",
       "      <td>0.382696</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.112366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858720</td>\n",
       "      <td>0.096670</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.154368</td>\n",
       "      <td>0.050471</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  installment  sub_grade  emp_length  annual_inc  \\\n",
       "0   0.139241     0  0.341900     0.128118        9.0         0.9    0.186581   \n",
       "1   0.113924     0  0.299065     0.104540        9.0         0.6    0.233788   \n",
       "2   0.367089     0  0.119938     0.299083        5.0         0.6    0.292235   \n",
       "3   0.240506     0  0.318536     0.213773       11.0         1.0    0.305722   \n",
       "4   0.139241     0  0.000389     0.112366        0.0         1.0    0.858720   \n",
       "\n",
       "        dti  open_acc  revol_bal  revol_util  total_acc  mort_acc  \\\n",
       "0  0.309085   0.56250   0.412459    0.222407   0.371795       0.0   \n",
       "1  0.292919   0.53125   0.102890    0.149750   0.358974       1.0   \n",
       "2  0.453767   0.43750   0.207708    0.221852   0.371795       1.0   \n",
       "3  0.566440   0.46875   0.441571    0.382696   0.410256       1.0   \n",
       "4  0.096670   0.21875   0.154368    0.050471   0.192308       1.0   \n",
       "\n",
       "   pub_rec_bankruptcies  Fico_average  year  home_ownership_hashed_0  \\\n",
       "0                   0.0         0.350  1994                      0.0   \n",
       "1                   0.0         0.450  1997                      0.0   \n",
       "2                   0.0         0.325  1996                      0.0   \n",
       "3                   0.0         0.300  1996                      0.0   \n",
       "4                   0.0         1.000  1995                      0.0   \n",
       "\n",
       "   home_ownership_hashed_1  home_ownership_hashed_2  home_ownership_hashed_3  \\\n",
       "0                      0.0                     -1.0                      0.0   \n",
       "1                      0.0                      1.0                      0.0   \n",
       "2                      0.0                      1.0                      0.0   \n",
       "3                      0.0                      1.0                      0.0   \n",
       "4                      0.0                      0.0                     -1.0   \n",
       "\n",
       "   home_ownership_hashed_4  home_ownership_hashed_5  home_ownership_hashed_6  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   home_ownership_hashed_7  home_ownership_hashed_8  home_ownership_hashed_9  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   verification_status_hashed_0  verification_status_hashed_1  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   verification_status_hashed_2  verification_status_hashed_3  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                          -1.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   verification_status_hashed_4  verification_status_hashed_5  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   verification_status_hashed_6  verification_status_hashed_7  \\\n",
       "0                           1.0                           0.0   \n",
       "1                           0.0                          -1.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                          -1.0   \n",
       "4                           1.0                           0.0   \n",
       "\n",
       "   verification_status_hashed_8  verification_status_hashed_9  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   purpose_hashed_0  purpose_hashed_1  purpose_hashed_2  purpose_hashed_3  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   purpose_hashed_4  purpose_hashed_5  purpose_hashed_6  purpose_hashed_7  \\\n",
       "0               0.0               0.0               0.0              -1.0   \n",
       "1               0.0               0.0               0.0              -1.0   \n",
       "2               0.0               0.0               0.0              -1.0   \n",
       "3               0.0               0.0               0.0              -1.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   purpose_hashed_8  purpose_hashed_9  initial_list_status_hashed_0  \\\n",
       "0               0.0               0.0                           0.0   \n",
       "1               0.0               0.0                           0.0   \n",
       "2               0.0               0.0                           0.0   \n",
       "3               0.0               0.0                           0.0   \n",
       "4               0.0               1.0                           0.0   \n",
       "\n",
       "   initial_list_status_hashed_1  initial_list_status_hashed_2  \\\n",
       "0                          -1.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                          -1.0                           0.0   \n",
       "3                          -1.0                           0.0   \n",
       "4                          -1.0                           0.0   \n",
       "\n",
       "   initial_list_status_hashed_3  initial_list_status_hashed_4  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           1.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   initial_list_status_hashed_5  initial_list_status_hashed_6  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   initial_list_status_hashed_7  initial_list_status_hashed_8  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   initial_list_status_hashed_9  application_type_hashed_0  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   application_type_hashed_1  application_type_hashed_2  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   application_type_hashed_3  application_type_hashed_4  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   application_type_hashed_5  application_type_hashed_6  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   application_type_hashed_7  application_type_hashed_8  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   application_type_hashed_9  region_hashed_0  region_hashed_1  \\\n",
       "0                       -1.0              0.0             -1.0   \n",
       "1                       -1.0              0.0             -1.0   \n",
       "2                       -1.0              0.0             -1.0   \n",
       "3                       -1.0              0.0             -1.0   \n",
       "4                       -1.0              0.0              0.0   \n",
       "\n",
       "   region_hashed_2  region_hashed_3  region_hashed_4  region_hashed_5  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0             -1.0   \n",
       "\n",
       "   region_hashed_6  region_hashed_7  region_hashed_8  region_hashed_9  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   loan_status  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fab08c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>Fico_average</th>\n",
       "      <th>year</th>\n",
       "      <th>home_ownership_hashed_0</th>\n",
       "      <th>home_ownership_hashed_1</th>\n",
       "      <th>home_ownership_hashed_2</th>\n",
       "      <th>home_ownership_hashed_3</th>\n",
       "      <th>home_ownership_hashed_4</th>\n",
       "      <th>home_ownership_hashed_5</th>\n",
       "      <th>home_ownership_hashed_6</th>\n",
       "      <th>home_ownership_hashed_7</th>\n",
       "      <th>home_ownership_hashed_8</th>\n",
       "      <th>home_ownership_hashed_9</th>\n",
       "      <th>verification_status_hashed_0</th>\n",
       "      <th>verification_status_hashed_1</th>\n",
       "      <th>verification_status_hashed_2</th>\n",
       "      <th>verification_status_hashed_3</th>\n",
       "      <th>verification_status_hashed_4</th>\n",
       "      <th>verification_status_hashed_5</th>\n",
       "      <th>verification_status_hashed_6</th>\n",
       "      <th>verification_status_hashed_7</th>\n",
       "      <th>verification_status_hashed_8</th>\n",
       "      <th>verification_status_hashed_9</th>\n",
       "      <th>purpose_hashed_0</th>\n",
       "      <th>purpose_hashed_1</th>\n",
       "      <th>purpose_hashed_2</th>\n",
       "      <th>purpose_hashed_3</th>\n",
       "      <th>purpose_hashed_4</th>\n",
       "      <th>purpose_hashed_5</th>\n",
       "      <th>purpose_hashed_6</th>\n",
       "      <th>purpose_hashed_7</th>\n",
       "      <th>purpose_hashed_8</th>\n",
       "      <th>purpose_hashed_9</th>\n",
       "      <th>initial_list_status_hashed_0</th>\n",
       "      <th>initial_list_status_hashed_1</th>\n",
       "      <th>initial_list_status_hashed_2</th>\n",
       "      <th>initial_list_status_hashed_3</th>\n",
       "      <th>initial_list_status_hashed_4</th>\n",
       "      <th>initial_list_status_hashed_5</th>\n",
       "      <th>initial_list_status_hashed_6</th>\n",
       "      <th>initial_list_status_hashed_7</th>\n",
       "      <th>initial_list_status_hashed_8</th>\n",
       "      <th>initial_list_status_hashed_9</th>\n",
       "      <th>application_type_hashed_0</th>\n",
       "      <th>application_type_hashed_1</th>\n",
       "      <th>application_type_hashed_2</th>\n",
       "      <th>application_type_hashed_3</th>\n",
       "      <th>application_type_hashed_4</th>\n",
       "      <th>application_type_hashed_5</th>\n",
       "      <th>application_type_hashed_6</th>\n",
       "      <th>application_type_hashed_7</th>\n",
       "      <th>application_type_hashed_8</th>\n",
       "      <th>application_type_hashed_9</th>\n",
       "      <th>region_hashed_0</th>\n",
       "      <th>region_hashed_1</th>\n",
       "      <th>region_hashed_2</th>\n",
       "      <th>region_hashed_3</th>\n",
       "      <th>region_hashed_4</th>\n",
       "      <th>region_hashed_5</th>\n",
       "      <th>region_hashed_6</th>\n",
       "      <th>region_hashed_7</th>\n",
       "      <th>region_hashed_8</th>\n",
       "      <th>region_hashed_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61519099</th>\n",
       "      <td>0.139241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061526</td>\n",
       "      <td>0.115102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.278747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184125</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.094950</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95696511</th>\n",
       "      <td>0.240506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104361</td>\n",
       "      <td>0.197158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.415872</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107662</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.475290</td>\n",
       "      <td>0.217970</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88312345</th>\n",
       "      <td>0.873418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.357477</td>\n",
       "      <td>0.523201</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.521526</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>0.492512</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044839</th>\n",
       "      <td>0.177215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515576</td>\n",
       "      <td>0.171521</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.247275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120272</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.139697</td>\n",
       "      <td>0.373267</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67919746</th>\n",
       "      <td>0.240506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075935</td>\n",
       "      <td>0.195016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.247275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.149303</td>\n",
       "      <td>0.291181</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt  term  int_rate  installment  sub_grade  emp_length  \\\n",
       "id                                                                        \n",
       "61519099   0.139241     0  0.061526     0.115102        2.0         0.6   \n",
       "95696511   0.240506     0  0.104361     0.197158        4.0         0.3   \n",
       "88312345   0.873418     1  0.357477     0.523201       13.0         0.9   \n",
       "9044839    0.177215     0  0.515576     0.171521       16.0         0.3   \n",
       "67919746   0.240506     0  0.075935     0.195016        3.0         0.6   \n",
       "\n",
       "          annual_inc  loan_status       dti  open_acc  revol_bal  revol_util  \\\n",
       "id                                                                             \n",
       "61519099    0.278747            1  0.184125   0.31250   0.094950    0.054908   \n",
       "95696511    0.415872            1  0.107662   0.62500   0.475290    0.217970   \n",
       "88312345    0.521526            1  0.224054   0.34375   0.546683    0.492512   \n",
       "9044839     0.247275            1  0.120272   0.31250   0.139697    0.373267   \n",
       "67919746    0.247275            1  0.074038   0.18750   0.149303    0.291181   \n",
       "\n",
       "          total_acc  mort_acc  pub_rec_bankruptcies  Fico_average  year  \\\n",
       "id                                                                        \n",
       "61519099   0.294872       1.0                   0.0         0.350  1993   \n",
       "95696511   0.551282       1.0                   0.0         0.250  2000   \n",
       "88312345   0.448718       1.0                   0.0         0.200  2002   \n",
       "9044839    0.205128       0.0                   0.0         0.200  2000   \n",
       "67919746   0.230769       1.0                   0.0         0.475  1978   \n",
       "\n",
       "          home_ownership_hashed_0  home_ownership_hashed_1  \\\n",
       "id                                                           \n",
       "61519099                      0.0                      0.0   \n",
       "95696511                      0.0                      0.0   \n",
       "88312345                      0.0                      0.0   \n",
       "9044839                       0.0                      0.0   \n",
       "67919746                      0.0                      0.0   \n",
       "\n",
       "          home_ownership_hashed_2  home_ownership_hashed_3  \\\n",
       "id                                                           \n",
       "61519099                     -1.0                      0.0   \n",
       "95696511                      1.0                      0.0   \n",
       "88312345                      1.0                      0.0   \n",
       "9044839                      -1.0                      0.0   \n",
       "67919746                      1.0                      0.0   \n",
       "\n",
       "          home_ownership_hashed_4  home_ownership_hashed_5  \\\n",
       "id                                                           \n",
       "61519099                      0.0                      0.0   \n",
       "95696511                      0.0                      0.0   \n",
       "88312345                      0.0                      0.0   \n",
       "9044839                       0.0                      0.0   \n",
       "67919746                      0.0                      0.0   \n",
       "\n",
       "          home_ownership_hashed_6  home_ownership_hashed_7  \\\n",
       "id                                                           \n",
       "61519099                      0.0                      0.0   \n",
       "95696511                      0.0                      0.0   \n",
       "88312345                      0.0                      0.0   \n",
       "9044839                       0.0                      0.0   \n",
       "67919746                      0.0                      0.0   \n",
       "\n",
       "          home_ownership_hashed_8  home_ownership_hashed_9  \\\n",
       "id                                                           \n",
       "61519099                      0.0                      0.0   \n",
       "95696511                      0.0                      0.0   \n",
       "88312345                      0.0                      0.0   \n",
       "9044839                       0.0                      0.0   \n",
       "67919746                      0.0                      0.0   \n",
       "\n",
       "          verification_status_hashed_0  verification_status_hashed_1  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          verification_status_hashed_2  verification_status_hashed_3  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                          -1.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                          -1.0                           0.0   \n",
       "\n",
       "          verification_status_hashed_4  verification_status_hashed_5  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          verification_status_hashed_6  verification_status_hashed_7  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                          -1.0   \n",
       "95696511                           0.0                          -1.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            1.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          verification_status_hashed_8  verification_status_hashed_9  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          purpose_hashed_0  purpose_hashed_1  purpose_hashed_2  \\\n",
       "id                                                               \n",
       "61519099               0.0               0.0               0.0   \n",
       "95696511               0.0               0.0               0.0   \n",
       "88312345               0.0               0.0               0.0   \n",
       "9044839                0.0               0.0               0.0   \n",
       "67919746               0.0               0.0               0.0   \n",
       "\n",
       "          purpose_hashed_3  purpose_hashed_4  purpose_hashed_5  \\\n",
       "id                                                               \n",
       "61519099               0.0               0.0               0.0   \n",
       "95696511               0.0               0.0               0.0   \n",
       "88312345               0.0               0.0               0.0   \n",
       "9044839                0.0               0.0               0.0   \n",
       "67919746               0.0               0.0               0.0   \n",
       "\n",
       "          purpose_hashed_6  purpose_hashed_7  purpose_hashed_8  \\\n",
       "id                                                               \n",
       "61519099               0.0              -1.0               0.0   \n",
       "95696511               0.0              -1.0               0.0   \n",
       "88312345               0.0               0.0               0.0   \n",
       "9044839                0.0               0.0               0.0   \n",
       "67919746               0.0              -1.0               0.0   \n",
       "\n",
       "          purpose_hashed_9  initial_list_status_hashed_0  \\\n",
       "id                                                         \n",
       "61519099               0.0                           0.0   \n",
       "95696511               0.0                           0.0   \n",
       "88312345               1.0                           0.0   \n",
       "9044839                1.0                           0.0   \n",
       "67919746               0.0                           0.0   \n",
       "\n",
       "          initial_list_status_hashed_1  initial_list_status_hashed_2  \\\n",
       "id                                                                     \n",
       "61519099                          -1.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                          -1.0                           0.0   \n",
       "9044839                           -1.0                           0.0   \n",
       "67919746                          -1.0                           0.0   \n",
       "\n",
       "          initial_list_status_hashed_3  initial_list_status_hashed_4  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           1.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          initial_list_status_hashed_5  initial_list_status_hashed_6  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          initial_list_status_hashed_7  initial_list_status_hashed_8  \\\n",
       "id                                                                     \n",
       "61519099                           0.0                           0.0   \n",
       "95696511                           0.0                           0.0   \n",
       "88312345                           0.0                           0.0   \n",
       "9044839                            0.0                           0.0   \n",
       "67919746                           0.0                           0.0   \n",
       "\n",
       "          initial_list_status_hashed_9  application_type_hashed_0  \\\n",
       "id                                                                  \n",
       "61519099                           0.0                        0.0   \n",
       "95696511                           0.0                        0.0   \n",
       "88312345                           0.0                        0.0   \n",
       "9044839                            0.0                        0.0   \n",
       "67919746                           0.0                        0.0   \n",
       "\n",
       "          application_type_hashed_1  application_type_hashed_2  \\\n",
       "id                                                               \n",
       "61519099                        0.0                        0.0   \n",
       "95696511                        0.0                        0.0   \n",
       "88312345                        0.0                        0.0   \n",
       "9044839                         0.0                        0.0   \n",
       "67919746                        0.0                        0.0   \n",
       "\n",
       "          application_type_hashed_3  application_type_hashed_4  \\\n",
       "id                                                               \n",
       "61519099                        0.0                        0.0   \n",
       "95696511                        0.0                        0.0   \n",
       "88312345                        0.0                        0.0   \n",
       "9044839                         0.0                        0.0   \n",
       "67919746                        0.0                        0.0   \n",
       "\n",
       "          application_type_hashed_5  application_type_hashed_6  \\\n",
       "id                                                               \n",
       "61519099                        0.0                        0.0   \n",
       "95696511                        0.0                        0.0   \n",
       "88312345                        0.0                        0.0   \n",
       "9044839                         0.0                        0.0   \n",
       "67919746                        0.0                        0.0   \n",
       "\n",
       "          application_type_hashed_7  application_type_hashed_8  \\\n",
       "id                                                               \n",
       "61519099                        0.0                        0.0   \n",
       "95696511                        0.0                        0.0   \n",
       "88312345                        0.0                        0.0   \n",
       "9044839                         0.0                        0.0   \n",
       "67919746                        0.0                        0.0   \n",
       "\n",
       "          application_type_hashed_9  region_hashed_0  region_hashed_1  \\\n",
       "id                                                                      \n",
       "61519099                       -1.0              0.0             -1.0   \n",
       "95696511                       -1.0              0.0             -1.0   \n",
       "88312345                       -1.0              0.0              0.0   \n",
       "9044839                        -1.0              0.0             -1.0   \n",
       "67919746                       -1.0              0.0             -1.0   \n",
       "\n",
       "          region_hashed_2  region_hashed_3  region_hashed_4  region_hashed_5  \\\n",
       "id                                                                             \n",
       "61519099              0.0              0.0              0.0              0.0   \n",
       "95696511              0.0              0.0              0.0              0.0   \n",
       "88312345              0.0              0.0              0.0             -1.0   \n",
       "9044839               0.0              0.0              0.0              0.0   \n",
       "67919746              0.0              0.0              0.0              0.0   \n",
       "\n",
       "          region_hashed_6  region_hashed_7  region_hashed_8  region_hashed_9  \n",
       "id                                                                            \n",
       "61519099              0.0              0.0              0.0              0.0  \n",
       "95696511              0.0              0.0              0.0              0.0  \n",
       "88312345              0.0              0.0              0.0              0.0  \n",
       "9044839               0.0              0.0              0.0              0.0  \n",
       "67919746              0.0              0.0              0.0              0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f9e9fe5-0ec4-4dc4-ac82-3b9890bd7f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1647260, 77)\n",
      "(269070, 77)\n"
     ]
    }
   ],
   "source": [
    "print(Train_df.shape)\n",
    "print(Test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7265a5b9-5b00-4ca3-a022-0a9b132efa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = Train_df.loc[:, Train_df.columns != 'loan_status'], Train_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f40eafb-2668-49df-b9d0-729a318ef0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = Test_df.loc[:, Test_df.columns != 'loan_status'], Test_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14ff25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import Perceptron,SGDClassifier,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc1c9e",
   "metadata": {},
   "source": [
    "# Define the models to compare\n",
    "models = {\n",
    "    'sgd': SGDClassifier(random_state=42, loss='log'),\n",
    "    'logistic_regression': LogisticRegression(solver='saga', random_state=52),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=52),\n",
    "    'random_forest': RandomForestClassifier(random_state=52),\n",
    "    'gradient_boosting': GradientBoostingClassifier(random_state=52),\n",
    "    'linear_discriminant_analysis': LinearDiscriminantAnalysis(),\n",
    "    'Xg-boost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=52),\n",
    "    'adaboost': AdaBoostClassifier(random_state=52),\n",
    "}\n",
    "\n",
    "# Create a DataFrame to store the evaluation scores\n",
    "scores = pd.DataFrame(columns=['Classifier', 'Data', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC', 'Brier_score'])\n",
    "\n",
    "# Loop through the models and train/test on the given data\n",
    "for name, model in models.items():\n",
    "    # Fit the model and get predictions for train and test\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model and store scores for train and test\n",
    "    for y_true, y_pred, data in zip([y_train, y_test], [y_train_pred, y_test_pred], ['Train', 'Test']):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        brier_score = brier_score_loss(y_true, y_pred)\n",
    "\n",
    "        row = pd.DataFrame({'Classifier': [name],\n",
    "                            'Data': [data],\n",
    "                            'Accuracy': [acc],\n",
    "                            'Precision': [prec],\n",
    "                            'Recall': [rec],\n",
    "                            'F1-score': [f1],\n",
    "                            'ROC AUC': [roc_auc],\n",
    "                            'Brier_score': [brier_score]})\n",
    "\n",
    "        scores = pd.concat([scores, row], ignore_index=True)\n",
    "\n",
    "        # Print the classification report for each model\n",
    "        if data == 'Test':\n",
    "            print(f\"Classification report for {name}:\")\n",
    "            print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Plot feature importance for tree-based models (RandomForest, GradientBoosting, XGBoost, and DecisionTree)\n",
    "    if name in [\"random_forest\", \"gradient_boosting\", \"Xg-boost\", \"decision_tree\"]:\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        indices = indices[:10]  # Select top 10 features\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(f\"Feature Importance: {name}\")\n",
    "        plt.bar(range(10), importances[indices], color=np.random.rand(3,))\n",
    "        plt.xticks(range(10), X_train.columns[indices], rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "# Generate ROC curve for all models\n",
    "plt.figure(figsize=(8, 8))\n",
    "for name, model in models.items():\n",
    "    y_probas = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probas)\n",
    "    roc_auc = roc_auc_score(y_test, y_probas)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC: {roc_auc:.2f})')\n",
    "\n",
    "# Show the combined ROC curve\n",
    "plt.title(\"ROC-AUC Curve for Different Models\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab3952",
   "metadata": {},
   "source": [
    "scores.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d404ee",
   "metadata": {},
   "source": [
    "# Calculate the number of rows and columns based on the number of classifiers\n",
    "num_classifiers = len(grouped_data)\n",
    "num_rows = (num_classifiers + 2) // 3  # Round up to the nearest integer\n",
    "num_cols = min(num_classifiers, 3)\n",
    "\n",
    "# Create subplots for each classifier\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 6 * num_rows), facecolor='w')\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each classifier and its corresponding data\n",
    "for i, (classifier, data) in enumerate(grouped_data):\n",
    "    # Set the subplot for the current classifier\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the horizontal bar graph with different colors for train and test data\n",
    "    y = np.arange(len(data.columns[2:]))  # Y-axis values\n",
    "    y_train = data[data['Data'] == 'Train'].values.flatten()[2:]  # Y-axis values for train data\n",
    "    y_test = data[data['Data'] == 'Test'].values.flatten()[2:]  # Y-axis values for test data\n",
    "    ax.barh(y - 0.2, y_train, height=0.4, label='Train', color=palette[i])\n",
    "    ax.barh(y + 0.2, y_test, height=0.4, label='Test', color=palette[i], alpha=0.7)\n",
    "    \n",
    "    # Set the y-axis labels\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(data.columns[2:])\n",
    "    \n",
    "    # Set the x-axis label\n",
    "    ax.set_xlabel('Scores')\n",
    "    \n",
    "    # Display the values on the bars\n",
    "    for j, train_val in enumerate(y_train):\n",
    "        ax.text(train_val, y[j] - 0.2, f'{train_val:.3f}', ha='center', va='center')\n",
    "    for j, test_val in enumerate(y_test):\n",
    "        ax.text(test_val, y[j] + 0.2, f'{test_val:.3f}', ha='center', va='center')\n",
    "    \n",
    "    # Set the title and legend for the current subplot\n",
    "    ax.set_title(classifier)\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "# Remove any unused subplots\n",
    "if num_classifiers < len(axes):\n",
    "    for j in range(num_classifiers, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "# Set the background color of the figure\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaa85a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END colsample_bytree=0.8370861069626263, learning_rate=0.6704285838459496, max_depth=5, min_child_weight=5, n_estimators=120, subsample=0.4404167763981929; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8370861069626263, learning_rate=0.6704285838459496, max_depth=5, min_child_weight=5, n_estimators=120, subsample=0.4404167763981929; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8370861069626263, learning_rate=0.6704285838459496, max_depth=5, min_child_weight=5, n_estimators=120, subsample=0.4404167763981929; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8370861069626263, learning_rate=0.6704285838459496, max_depth=5, min_child_weight=5, n_estimators=120, subsample=0.4404167763981929; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8370861069626263, learning_rate=0.6704285838459496, max_depth=5, min_child_weight=5, n_estimators=120, subsample=0.4404167763981929; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.6403950683025824, learning_rate=0.13485016730091967, max_depth=7, min_child_weight=4, n_estimators=459, subsample=0.9372653200164409; total time= 8.3min\n",
      "[CV] END colsample_bytree=0.6403950683025824, learning_rate=0.13485016730091967, max_depth=7, min_child_weight=4, n_estimators=459, subsample=0.9372653200164409; total time= 8.1min\n",
      "[CV] END colsample_bytree=0.6403950683025824, learning_rate=0.13485016730091967, max_depth=7, min_child_weight=4, n_estimators=459, subsample=0.9372653200164409; total time= 8.0min\n",
      "[CV] END colsample_bytree=0.6403950683025824, learning_rate=0.13485016730091967, max_depth=7, min_child_weight=4, n_estimators=459, subsample=0.9372653200164409; total time= 8.0min\n",
      "[CV] END colsample_bytree=0.6403950683025824, learning_rate=0.13485016730091967, max_depth=7, min_child_weight=4, n_estimators=459, subsample=0.9372653200164409; total time= 8.0min\n",
      "[CV] END colsample_bytree=0.5185260448662222, learning_rate=0.6819459112971965, max_depth=6, min_child_weight=2, n_estimators=291, subsample=1.1929904033620957; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5185260448662222, learning_rate=0.6819459112971965, max_depth=6, min_child_weight=2, n_estimators=291, subsample=1.1929904033620957; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5185260448662222, learning_rate=0.6819459112971965, max_depth=6, min_child_weight=2, n_estimators=291, subsample=1.1929904033620957; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5185260448662222, learning_rate=0.6819459112971965, max_depth=6, min_child_weight=2, n_estimators=291, subsample=1.1929904033620957; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5185260448662222, learning_rate=0.6819459112971965, max_depth=6, min_child_weight=2, n_estimators=291, subsample=1.1929904033620957; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0557333586649449, learning_rate=0.46699189629296856, max_depth=7, min_child_weight=4, n_estimators=444, subsample=0.5621062261782377; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0557333586649449, learning_rate=0.46699189629296856, max_depth=7, min_child_weight=4, n_estimators=444, subsample=0.5621062261782377; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0557333586649449, learning_rate=0.46699189629296856, max_depth=7, min_child_weight=4, n_estimators=444, subsample=0.5621062261782377; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0557333586649449, learning_rate=0.46699189629296856, max_depth=7, min_child_weight=4, n_estimators=444, subsample=0.5621062261782377; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0557333586649449, learning_rate=0.46699189629296856, max_depth=7, min_child_weight=4, n_estimators=444, subsample=0.5621062261782377; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0506676052501416, learning_rate=0.1836963163912251, max_depth=6, min_child_weight=4, n_estimators=370, subsample=0.7104629857953324; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0506676052501416, learning_rate=0.1836963163912251, max_depth=6, min_child_weight=4, n_estimators=370, subsample=0.7104629857953324; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0506676052501416, learning_rate=0.1836963163912251, max_depth=6, min_child_weight=4, n_estimators=370, subsample=0.7104629857953324; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0506676052501416, learning_rate=0.1836963163912251, max_depth=6, min_child_weight=4, n_estimators=370, subsample=0.7104629857953324; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0506676052501416, learning_rate=0.1836963163912251, max_depth=6, min_child_weight=4, n_estimators=370, subsample=0.7104629857953324; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2066583652537122, learning_rate=0.21980426929501584, max_depth=9, min_child_weight=4, n_estimators=419, subsample=0.7200866039231819; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2066583652537122, learning_rate=0.21980426929501584, max_depth=9, min_child_weight=4, n_estimators=419, subsample=0.7200866039231819; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2066583652537122, learning_rate=0.21980426929501584, max_depth=9, min_child_weight=4, n_estimators=419, subsample=0.7200866039231819; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2066583652537122, learning_rate=0.21980426929501584, max_depth=9, min_child_weight=4, n_estimators=419, subsample=0.7200866039231819; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2066583652537122, learning_rate=0.21980426929501584, max_depth=9, min_child_weight=4, n_estimators=419, subsample=0.7200866039231819; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2739463660626886, learning_rate=0.5081845231526678, max_depth=3, min_child_weight=2, n_estimators=487, subsample=1.1479815801163675; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2739463660626886, learning_rate=0.5081845231526678, max_depth=3, min_child_weight=2, n_estimators=487, subsample=1.1479815801163675; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2739463660626886, learning_rate=0.5081845231526678, max_depth=3, min_child_weight=2, n_estimators=487, subsample=1.1479815801163675; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2739463660626886, learning_rate=0.5081845231526678, max_depth=3, min_child_weight=2, n_estimators=487, subsample=1.1479815801163675; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2739463660626886, learning_rate=0.5081845231526678, max_depth=3, min_child_weight=2, n_estimators=487, subsample=1.1479815801163675; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0069593960609855, learning_rate=0.3312499015239496, max_depth=4, min_child_weight=5, n_estimators=485, subsample=0.9158097238609413; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0069593960609855, learning_rate=0.3312499015239496, max_depth=4, min_child_weight=5, n_estimators=485, subsample=0.9158097238609413; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0069593960609855, learning_rate=0.3312499015239496, max_depth=4, min_child_weight=5, n_estimators=485, subsample=0.9158097238609413; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0069593960609855, learning_rate=0.3312499015239496, max_depth=4, min_child_weight=5, n_estimators=485, subsample=0.9158097238609413; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0069593960609855, learning_rate=0.3312499015239496, max_depth=4, min_child_weight=5, n_estimators=485, subsample=0.9158097238609413; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8961372443656412, learning_rate=0.1732229409068673, max_depth=7, min_child_weight=3, n_estimators=305, subsample=0.6519545468159167; total time= 7.7min\n",
      "[CV] END colsample_bytree=0.8961372443656412, learning_rate=0.1732229409068673, max_depth=7, min_child_weight=3, n_estimators=305, subsample=0.6519545468159167; total time= 7.5min\n",
      "[CV] END colsample_bytree=0.8961372443656412, learning_rate=0.1732229409068673, max_depth=7, min_child_weight=3, n_estimators=305, subsample=0.6519545468159167; total time= 7.6min\n",
      "[CV] END colsample_bytree=0.8961372443656412, learning_rate=0.1732229409068673, max_depth=7, min_child_weight=3, n_estimators=305, subsample=0.6519545468159167; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.8961372443656412, learning_rate=0.1732229409068673, max_depth=7, min_child_weight=3, n_estimators=305, subsample=0.6519545468159167; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.6640124790092561, learning_rate=0.5532168461905914, max_depth=8, min_child_weight=2, n_estimators=359, subsample=0.46636900997297437; total time= 7.7min\n",
      "[CV] END colsample_bytree=0.6640124790092561, learning_rate=0.5532168461905914, max_depth=8, min_child_weight=2, n_estimators=359, subsample=0.46636900997297437; total time= 7.6min\n",
      "[CV] END colsample_bytree=0.6640124790092561, learning_rate=0.5532168461905914, max_depth=8, min_child_weight=2, n_estimators=359, subsample=0.46636900997297437; total time= 7.6min\n",
      "[CV] END colsample_bytree=0.6640124790092561, learning_rate=0.5532168461905914, max_depth=8, min_child_weight=2, n_estimators=359, subsample=0.46636900997297437; total time= 7.6min\n",
      "[CV] END colsample_bytree=0.6640124790092561, learning_rate=0.5532168461905914, max_depth=8, min_child_weight=2, n_estimators=359, subsample=0.46636900997297437; total time= 7.6min\n",
      "[CV] END colsample_bytree=1.3726261649881026, learning_rate=0.5650796940166687, max_depth=4, min_child_weight=2, n_estimators=369, subsample=0.9545447962707787; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3726261649881026, learning_rate=0.5650796940166687, max_depth=4, min_child_weight=2, n_estimators=369, subsample=0.9545447962707787; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3726261649881026, learning_rate=0.5650796940166687, max_depth=4, min_child_weight=2, n_estimators=369, subsample=0.9545447962707787; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3726261649881026, learning_rate=0.5650796940166687, max_depth=4, min_child_weight=2, n_estimators=369, subsample=0.9545447962707787; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3726261649881026, learning_rate=0.5650796940166687, max_depth=4, min_child_weight=2, n_estimators=369, subsample=0.9545447962707787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7938866919252519, learning_rate=0.44226638464323964, max_depth=6, min_child_weight=1, n_estimators=289, subsample=0.5927972976869379; total time= 5.5min\n",
      "[CV] END colsample_bytree=0.7938866919252519, learning_rate=0.44226638464323964, max_depth=6, min_child_weight=1, n_estimators=289, subsample=0.5927972976869379; total time= 5.5min\n",
      "[CV] END colsample_bytree=0.7938866919252519, learning_rate=0.44226638464323964, max_depth=6, min_child_weight=1, n_estimators=289, subsample=0.5927972976869379; total time= 5.7min\n",
      "[CV] END colsample_bytree=0.7938866919252519, learning_rate=0.44226638464323964, max_depth=6, min_child_weight=1, n_estimators=289, subsample=0.5927972976869379; total time= 5.6min\n",
      "[CV] END colsample_bytree=0.7938866919252519, learning_rate=0.44226638464323964, max_depth=6, min_child_weight=1, n_estimators=289, subsample=0.5927972976869379; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.8498095607205338, learning_rate=0.2628094190643375, max_depth=7, min_child_weight=2, n_estimators=316, subsample=0.5528410587186428; total time= 7.5min\n",
      "[CV] END colsample_bytree=0.8498095607205338, learning_rate=0.2628094190643375, max_depth=7, min_child_weight=2, n_estimators=316, subsample=0.5528410587186428; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.8498095607205338, learning_rate=0.2628094190643375, max_depth=7, min_child_weight=2, n_estimators=316, subsample=0.5528410587186428; total time= 7.3min\n",
      "[CV] END colsample_bytree=0.8498095607205338, learning_rate=0.2628094190643375, max_depth=7, min_child_weight=2, n_estimators=316, subsample=0.5528410587186428; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.8498095607205338, learning_rate=0.2628094190643375, max_depth=7, min_child_weight=2, n_estimators=316, subsample=0.5528410587186428; total time= 7.3min\n",
      "[CV] END colsample_bytree=0.9884264748424236, learning_rate=0.18455453498485758, max_depth=9, min_child_weight=5, n_estimators=164, subsample=0.3140727660670745; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.9884264748424236, learning_rate=0.18455453498485758, max_depth=9, min_child_weight=5, n_estimators=164, subsample=0.3140727660670745; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.9884264748424236, learning_rate=0.18455453498485758, max_depth=9, min_child_weight=5, n_estimators=164, subsample=0.3140727660670745; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.9884264748424236, learning_rate=0.18455453498485758, max_depth=9, min_child_weight=5, n_estimators=164, subsample=0.3140727660670745; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.9884264748424236, learning_rate=0.18455453498485758, max_depth=9, min_child_weight=5, n_estimators=164, subsample=0.3140727660670745; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.8810613326357326, learning_rate=0.3369289109053418, max_depth=9, min_child_weight=3, n_estimators=180, subsample=0.940207757473785; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.8810613326357326, learning_rate=0.3369289109053418, max_depth=9, min_child_weight=3, n_estimators=180, subsample=0.940207757473785; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.8810613326357326, learning_rate=0.3369289109053418, max_depth=9, min_child_weight=3, n_estimators=180, subsample=0.940207757473785; total time= 5.3min\n",
      "[CV] END colsample_bytree=0.8810613326357326, learning_rate=0.3369289109053418, max_depth=9, min_child_weight=3, n_estimators=180, subsample=0.940207757473785; total time= 5.3min\n",
      "[CV] END colsample_bytree=0.8810613326357326, learning_rate=0.3369289109053418, max_depth=9, min_child_weight=3, n_estimators=180, subsample=0.940207757473785; total time= 5.3min\n",
      "[CV] END colsample_bytree=1.211157986478085, learning_rate=0.46357598486860685, max_depth=4, min_child_weight=2, n_estimators=140, subsample=1.1234637079894028; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.211157986478085, learning_rate=0.46357598486860685, max_depth=4, min_child_weight=2, n_estimators=140, subsample=1.1234637079894028; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.211157986478085, learning_rate=0.46357598486860685, max_depth=4, min_child_weight=2, n_estimators=140, subsample=1.1234637079894028; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.211157986478085, learning_rate=0.46357598486860685, max_depth=4, min_child_weight=2, n_estimators=140, subsample=1.1234637079894028; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.211157986478085, learning_rate=0.46357598486860685, max_depth=4, min_child_weight=2, n_estimators=140, subsample=1.1234637079894028; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2650347200108194, learning_rate=0.369670404482922, max_depth=3, min_child_weight=5, n_estimators=198, subsample=0.8321680089369543; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2650347200108194, learning_rate=0.369670404482922, max_depth=3, min_child_weight=5, n_estimators=198, subsample=0.8321680089369543; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2650347200108194, learning_rate=0.369670404482922, max_depth=3, min_child_weight=5, n_estimators=198, subsample=0.8321680089369543; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2650347200108194, learning_rate=0.369670404482922, max_depth=3, min_child_weight=5, n_estimators=198, subsample=0.8321680089369543; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2650347200108194, learning_rate=0.369670404482922, max_depth=3, min_child_weight=5, n_estimators=198, subsample=0.8321680089369543; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7472496136910578, learning_rate=0.43674605550862067, max_depth=5, min_child_weight=5, n_estimators=230, subsample=0.9847065437552076; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.7472496136910578, learning_rate=0.43674605550862067, max_depth=5, min_child_weight=5, n_estimators=230, subsample=0.9847065437552076; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.7472496136910578, learning_rate=0.43674605550862067, max_depth=5, min_child_weight=5, n_estimators=230, subsample=0.9847065437552076; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.7472496136910578, learning_rate=0.43674605550862067, max_depth=5, min_child_weight=5, n_estimators=230, subsample=0.9847065437552076; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.7472496136910578, learning_rate=0.43674605550862067, max_depth=5, min_child_weight=5, n_estimators=230, subsample=0.9847065437552076; total time= 3.2min\n",
      "[CV] END colsample_bytree=1.0051494778125467, learning_rate=0.5625803079727366, max_depth=9, min_child_weight=3, n_estimators=492, subsample=0.9395966007172087; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0051494778125467, learning_rate=0.5625803079727366, max_depth=9, min_child_weight=3, n_estimators=492, subsample=0.9395966007172087; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0051494778125467, learning_rate=0.5625803079727366, max_depth=9, min_child_weight=3, n_estimators=492, subsample=0.9395966007172087; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0051494778125467, learning_rate=0.5625803079727366, max_depth=9, min_child_weight=3, n_estimators=492, subsample=0.9395966007172087; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0051494778125467, learning_rate=0.5625803079727366, max_depth=9, min_child_weight=3, n_estimators=492, subsample=0.9395966007172087; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5998017387306482, learning_rate=0.3636019011194621, max_depth=5, min_child_weight=1, n_estimators=151, subsample=0.8069480147787453; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5998017387306482, learning_rate=0.3636019011194621, max_depth=5, min_child_weight=1, n_estimators=151, subsample=0.8069480147787453; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5998017387306482, learning_rate=0.3636019011194621, max_depth=5, min_child_weight=1, n_estimators=151, subsample=0.8069480147787453; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5998017387306482, learning_rate=0.3636019011194621, max_depth=5, min_child_weight=1, n_estimators=151, subsample=0.8069480147787453; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5998017387306482, learning_rate=0.3636019011194621, max_depth=5, min_child_weight=1, n_estimators=151, subsample=0.8069480147787453; total time= 1.9min\n",
      "[CV] END colsample_bytree=1.1259644777835147, learning_rate=0.18359887264352542, max_depth=9, min_child_weight=5, n_estimators=242, subsample=0.9799960246887438; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1259644777835147, learning_rate=0.18359887264352542, max_depth=9, min_child_weight=5, n_estimators=242, subsample=0.9799960246887438; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1259644777835147, learning_rate=0.18359887264352542, max_depth=9, min_child_weight=5, n_estimators=242, subsample=0.9799960246887438; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1259644777835147, learning_rate=0.18359887264352542, max_depth=9, min_child_weight=5, n_estimators=242, subsample=0.9799960246887438; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1259644777835147, learning_rate=0.18359887264352542, max_depth=9, min_child_weight=5, n_estimators=242, subsample=0.9799960246887438; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7059183489424602, learning_rate=0.1461879458972758, max_depth=5, min_child_weight=3, n_estimators=185, subsample=1.0924210551137319; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7059183489424602, learning_rate=0.1461879458972758, max_depth=5, min_child_weight=3, n_estimators=185, subsample=1.0924210551137319; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7059183489424602, learning_rate=0.1461879458972758, max_depth=5, min_child_weight=3, n_estimators=185, subsample=1.0924210551137319; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7059183489424602, learning_rate=0.1461879458972758, max_depth=5, min_child_weight=3, n_estimators=185, subsample=1.0924210551137319; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7059183489424602, learning_rate=0.1461879458972758, max_depth=5, min_child_weight=3, n_estimators=185, subsample=1.0924210551137319; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.061918643320414, learning_rate=0.27738021150262837, max_depth=7, min_child_weight=4, n_estimators=127, subsample=0.4965963934951502; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.061918643320414, learning_rate=0.27738021150262837, max_depth=7, min_child_weight=4, n_estimators=127, subsample=0.4965963934951502; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.061918643320414, learning_rate=0.27738021150262837, max_depth=7, min_child_weight=4, n_estimators=127, subsample=0.4965963934951502; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.061918643320414, learning_rate=0.27738021150262837, max_depth=7, min_child_weight=4, n_estimators=127, subsample=0.4965963934951502; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.061918643320414, learning_rate=0.27738021150262837, max_depth=7, min_child_weight=4, n_estimators=127, subsample=0.4965963934951502; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8748589530833296, learning_rate=0.6299681553513209, max_depth=4, min_child_weight=4, n_estimators=330, subsample=1.1161455973911787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8748589530833296, learning_rate=0.6299681553513209, max_depth=4, min_child_weight=4, n_estimators=330, subsample=1.1161455973911787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8748589530833296, learning_rate=0.6299681553513209, max_depth=4, min_child_weight=4, n_estimators=330, subsample=1.1161455973911787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8748589530833296, learning_rate=0.6299681553513209, max_depth=4, min_child_weight=4, n_estimators=330, subsample=1.1161455973911787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8748589530833296, learning_rate=0.6299681553513209, max_depth=4, min_child_weight=4, n_estimators=330, subsample=1.1161455973911787; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7449190244461718, learning_rate=0.48861407232481735, max_depth=3, min_child_weight=4, n_estimators=332, subsample=0.5743031323422261; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.7449190244461718, learning_rate=0.48861407232481735, max_depth=3, min_child_weight=4, n_estimators=332, subsample=0.5743031323422261; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.7449190244461718, learning_rate=0.48861407232481735, max_depth=3, min_child_weight=4, n_estimators=332, subsample=0.5743031323422261; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.7449190244461718, learning_rate=0.48861407232481735, max_depth=3, min_child_weight=4, n_estimators=332, subsample=0.5743031323422261; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.7449190244461718, learning_rate=0.48861407232481735, max_depth=3, min_child_weight=4, n_estimators=332, subsample=0.5743031323422261; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.6481902678286475, learning_rate=0.42045365162526516, max_depth=8, min_child_weight=5, n_estimators=324, subsample=0.4078788306003145; total time= 6.6min\n",
      "[CV] END colsample_bytree=0.6481902678286475, learning_rate=0.42045365162526516, max_depth=8, min_child_weight=5, n_estimators=324, subsample=0.4078788306003145; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.6481902678286475, learning_rate=0.42045365162526516, max_depth=8, min_child_weight=5, n_estimators=324, subsample=0.4078788306003145; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.6481902678286475, learning_rate=0.42045365162526516, max_depth=8, min_child_weight=5, n_estimators=324, subsample=0.4078788306003145; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.6481902678286475, learning_rate=0.42045365162526516, max_depth=8, min_child_weight=5, n_estimators=324, subsample=0.4078788306003145; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.8038536542632652, learning_rate=0.6657458223475115, max_depth=8, min_child_weight=1, n_estimators=279, subsample=0.6272666421413646; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.8038536542632652, learning_rate=0.6657458223475115, max_depth=8, min_child_weight=1, n_estimators=279, subsample=0.6272666421413646; total time= 7.3min\n",
      "[CV] END colsample_bytree=0.8038536542632652, learning_rate=0.6657458223475115, max_depth=8, min_child_weight=1, n_estimators=279, subsample=0.6272666421413646; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.8038536542632652, learning_rate=0.6657458223475115, max_depth=8, min_child_weight=1, n_estimators=279, subsample=0.6272666421413646; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.8038536542632652, learning_rate=0.6657458223475115, max_depth=8, min_child_weight=1, n_estimators=279, subsample=0.6272666421413646; total time= 7.2min\n",
      "[CV] END colsample_bytree=1.3746038744488647, learning_rate=0.6774683769652667, max_depth=8, min_child_weight=2, n_estimators=486, subsample=0.5707904788350927; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3746038744488647, learning_rate=0.6774683769652667, max_depth=8, min_child_weight=2, n_estimators=486, subsample=0.5707904788350927; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3746038744488647, learning_rate=0.6774683769652667, max_depth=8, min_child_weight=2, n_estimators=486, subsample=0.5707904788350927; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3746038744488647, learning_rate=0.6774683769652667, max_depth=8, min_child_weight=2, n_estimators=486, subsample=0.5707904788350927; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3746038744488647, learning_rate=0.6774683769652667, max_depth=8, min_child_weight=2, n_estimators=486, subsample=0.5707904788350927; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7563564449397209, learning_rate=0.12213216841271968, max_depth=3, min_child_weight=2, n_estimators=229, subsample=0.6699333119864082; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7563564449397209, learning_rate=0.12213216841271968, max_depth=3, min_child_weight=2, n_estimators=229, subsample=0.6699333119864082; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7563564449397209, learning_rate=0.12213216841271968, max_depth=3, min_child_weight=2, n_estimators=229, subsample=0.6699333119864082; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7563564449397209, learning_rate=0.12213216841271968, max_depth=3, min_child_weight=2, n_estimators=229, subsample=0.6699333119864082; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7563564449397209, learning_rate=0.12213216841271968, max_depth=3, min_child_weight=2, n_estimators=229, subsample=0.6699333119864082; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.5297456596104936, learning_rate=0.3070427488160098, max_depth=3, min_child_weight=3, n_estimators=225, subsample=0.4304053848821008; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5297456596104936, learning_rate=0.3070427488160098, max_depth=3, min_child_weight=3, n_estimators=225, subsample=0.4304053848821008; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.5297456596104936, learning_rate=0.3070427488160098, max_depth=3, min_child_weight=3, n_estimators=225, subsample=0.4304053848821008; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.5297456596104936, learning_rate=0.3070427488160098, max_depth=3, min_child_weight=3, n_estimators=225, subsample=0.4304053848821008; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.5297456596104936, learning_rate=0.3070427488160098, max_depth=3, min_child_weight=3, n_estimators=225, subsample=0.4304053848821008; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.9405074842498067, learning_rate=0.6913902724663604, max_depth=9, min_child_weight=4, n_estimators=302, subsample=0.632689010455264; total time=10.3min\n",
      "[CV] END colsample_bytree=0.9405074842498067, learning_rate=0.6913902724663604, max_depth=9, min_child_weight=4, n_estimators=302, subsample=0.632689010455264; total time=10.1min\n",
      "[CV] END colsample_bytree=0.9405074842498067, learning_rate=0.6913902724663604, max_depth=9, min_child_weight=4, n_estimators=302, subsample=0.632689010455264; total time=10.0min\n",
      "[CV] END colsample_bytree=0.9405074842498067, learning_rate=0.6913902724663604, max_depth=9, min_child_weight=4, n_estimators=302, subsample=0.632689010455264; total time=10.3min\n",
      "[CV] END colsample_bytree=0.9405074842498067, learning_rate=0.6913902724663604, max_depth=9, min_child_weight=4, n_estimators=302, subsample=0.632689010455264; total time=10.2min\n",
      "[CV] END colsample_bytree=0.7179439444496833, learning_rate=0.5818838538279375, max_depth=7, min_child_weight=4, n_estimators=197, subsample=0.8701767396848052; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7179439444496833, learning_rate=0.5818838538279375, max_depth=7, min_child_weight=4, n_estimators=197, subsample=0.8701767396848052; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.7179439444496833, learning_rate=0.5818838538279375, max_depth=7, min_child_weight=4, n_estimators=197, subsample=0.8701767396848052; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.7179439444496833, learning_rate=0.5818838538279375, max_depth=7, min_child_weight=4, n_estimators=197, subsample=0.8701767396848052; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.7179439444496833, learning_rate=0.5818838538279375, max_depth=7, min_child_weight=4, n_estimators=197, subsample=0.8701767396848052; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.9821972156672827, learning_rate=0.154173862032645, max_depth=3, min_child_weight=1, n_estimators=223, subsample=0.7573788990666468; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9821972156672827, learning_rate=0.154173862032645, max_depth=3, min_child_weight=1, n_estimators=223, subsample=0.7573788990666468; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9821972156672827, learning_rate=0.154173862032645, max_depth=3, min_child_weight=1, n_estimators=223, subsample=0.7573788990666468; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9821972156672827, learning_rate=0.154173862032645, max_depth=3, min_child_weight=1, n_estimators=223, subsample=0.7573788990666468; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9821972156672827, learning_rate=0.154173862032645, max_depth=3, min_child_weight=1, n_estimators=223, subsample=0.7573788990666468; total time= 2.5min\n",
      "[CV] END colsample_bytree=1.1262315261117937, learning_rate=0.6150152828882318, max_depth=6, min_child_weight=3, n_estimators=445, subsample=0.7608837524693528; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1262315261117937, learning_rate=0.6150152828882318, max_depth=6, min_child_weight=3, n_estimators=445, subsample=0.7608837524693528; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1262315261117937, learning_rate=0.6150152828882318, max_depth=6, min_child_weight=3, n_estimators=445, subsample=0.7608837524693528; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1262315261117937, learning_rate=0.6150152828882318, max_depth=6, min_child_weight=3, n_estimators=445, subsample=0.7608837524693528; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1262315261117937, learning_rate=0.6150152828882318, max_depth=6, min_child_weight=3, n_estimators=445, subsample=0.7608837524693528; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7038461976781442, learning_rate=0.4871036742456699, max_depth=6, min_child_weight=1, n_estimators=227, subsample=0.765976215474732; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.7038461976781442, learning_rate=0.4871036742456699, max_depth=6, min_child_weight=1, n_estimators=227, subsample=0.765976215474732; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.7038461976781442, learning_rate=0.4871036742456699, max_depth=6, min_child_weight=1, n_estimators=227, subsample=0.765976215474732; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.7038461976781442, learning_rate=0.4871036742456699, max_depth=6, min_child_weight=1, n_estimators=227, subsample=0.765976215474732; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.7038461976781442, learning_rate=0.4871036742456699, max_depth=6, min_child_weight=1, n_estimators=227, subsample=0.765976215474732; total time= 3.8min\n",
      "[CV] END colsample_bytree=1.2539390953165952, learning_rate=0.5054140702235684, max_depth=3, min_child_weight=1, n_estimators=250, subsample=0.7873031764448093; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2539390953165952, learning_rate=0.5054140702235684, max_depth=3, min_child_weight=1, n_estimators=250, subsample=0.7873031764448093; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2539390953165952, learning_rate=0.5054140702235684, max_depth=3, min_child_weight=1, n_estimators=250, subsample=0.7873031764448093; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2539390953165952, learning_rate=0.5054140702235684, max_depth=3, min_child_weight=1, n_estimators=250, subsample=0.7873031764448093; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2539390953165952, learning_rate=0.5054140702235684, max_depth=3, min_child_weight=1, n_estimators=250, subsample=0.7873031764448093; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.126205959410574, learning_rate=0.2371300130783798, max_depth=4, min_child_weight=1, n_estimators=159, subsample=0.5347462573473681; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.126205959410574, learning_rate=0.2371300130783798, max_depth=4, min_child_weight=1, n_estimators=159, subsample=0.5347462573473681; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.126205959410574, learning_rate=0.2371300130783798, max_depth=4, min_child_weight=1, n_estimators=159, subsample=0.5347462573473681; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.126205959410574, learning_rate=0.2371300130783798, max_depth=4, min_child_weight=1, n_estimators=159, subsample=0.5347462573473681; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.126205959410574, learning_rate=0.2371300130783798, max_depth=4, min_child_weight=1, n_estimators=159, subsample=0.5347462573473681; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.396628329782132, learning_rate=0.6792516107732761, max_depth=7, min_child_weight=5, n_estimators=259, subsample=0.8697913115459412; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.396628329782132, learning_rate=0.6792516107732761, max_depth=7, min_child_weight=5, n_estimators=259, subsample=0.8697913115459412; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.396628329782132, learning_rate=0.6792516107732761, max_depth=7, min_child_weight=5, n_estimators=259, subsample=0.8697913115459412; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.396628329782132, learning_rate=0.6792516107732761, max_depth=7, min_child_weight=5, n_estimators=259, subsample=0.8697913115459412; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.396628329782132, learning_rate=0.6792516107732761, max_depth=7, min_child_weight=5, n_estimators=259, subsample=0.8697913115459412; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8051268119438306, learning_rate=0.30952574476759653, max_depth=5, min_child_weight=4, n_estimators=251, subsample=0.6640573144099711; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.8051268119438306, learning_rate=0.30952574476759653, max_depth=5, min_child_weight=4, n_estimators=251, subsample=0.6640573144099711; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.8051268119438306, learning_rate=0.30952574476759653, max_depth=5, min_child_weight=4, n_estimators=251, subsample=0.6640573144099711; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.8051268119438306, learning_rate=0.30952574476759653, max_depth=5, min_child_weight=4, n_estimators=251, subsample=0.6640573144099711; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.8051268119438306, learning_rate=0.30952574476759653, max_depth=5, min_child_weight=4, n_estimators=251, subsample=0.6640573144099711; total time= 4.0min\n",
      "[CV] END colsample_bytree=1.2989930888848638, learning_rate=0.6105570692605076, max_depth=3, min_child_weight=4, n_estimators=203, subsample=0.8457861536936309; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2989930888848638, learning_rate=0.6105570692605076, max_depth=3, min_child_weight=4, n_estimators=203, subsample=0.8457861536936309; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2989930888848638, learning_rate=0.6105570692605076, max_depth=3, min_child_weight=4, n_estimators=203, subsample=0.8457861536936309; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2989930888848638, learning_rate=0.6105570692605076, max_depth=3, min_child_weight=4, n_estimators=203, subsample=0.8457861536936309; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2989930888848638, learning_rate=0.6105570692605076, max_depth=3, min_child_weight=4, n_estimators=203, subsample=0.8457861536936309; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5082773464549667, learning_rate=0.16088292571961926, max_depth=5, min_child_weight=1, n_estimators=448, subsample=0.5555288772637191; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.5082773464549667, learning_rate=0.16088292571961926, max_depth=5, min_child_weight=1, n_estimators=448, subsample=0.5555288772637191; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.5082773464549667, learning_rate=0.16088292571961926, max_depth=5, min_child_weight=1, n_estimators=448, subsample=0.5555288772637191; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.5082773464549667, learning_rate=0.16088292571961926, max_depth=5, min_child_weight=1, n_estimators=448, subsample=0.5555288772637191; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.5082773464549667, learning_rate=0.16088292571961926, max_depth=5, min_child_weight=1, n_estimators=448, subsample=0.5555288772637191; total time= 4.9min\n",
      "[CV] END colsample_bytree=0.7748274743099541, learning_rate=0.391368252151736, max_depth=5, min_child_weight=5, n_estimators=268, subsample=0.45833272740961084; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7748274743099541, learning_rate=0.391368252151736, max_depth=5, min_child_weight=5, n_estimators=268, subsample=0.45833272740961084; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7748274743099541, learning_rate=0.391368252151736, max_depth=5, min_child_weight=5, n_estimators=268, subsample=0.45833272740961084; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7748274743099541, learning_rate=0.391368252151736, max_depth=5, min_child_weight=5, n_estimators=268, subsample=0.45833272740961084; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7748274743099541, learning_rate=0.391368252151736, max_depth=5, min_child_weight=5, n_estimators=268, subsample=0.45833272740961084; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.5162678272539688, learning_rate=0.3963362291100607, max_depth=6, min_child_weight=3, n_estimators=227, subsample=0.8114777430019244; total time= 3.0min\n",
      "[CV] END colsample_bytree=0.5162678272539688, learning_rate=0.3963362291100607, max_depth=6, min_child_weight=3, n_estimators=227, subsample=0.8114777430019244; total time= 3.0min\n",
      "[CV] END colsample_bytree=0.5162678272539688, learning_rate=0.3963362291100607, max_depth=6, min_child_weight=3, n_estimators=227, subsample=0.8114777430019244; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.5162678272539688, learning_rate=0.3963362291100607, max_depth=6, min_child_weight=3, n_estimators=227, subsample=0.8114777430019244; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.5162678272539688, learning_rate=0.3963362291100607, max_depth=6, min_child_weight=3, n_estimators=227, subsample=0.8114777430019244; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.5843072910452832, learning_rate=0.3206294818356601, max_depth=9, min_child_weight=5, n_estimators=150, subsample=1.102841899659402; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5843072910452832, learning_rate=0.3206294818356601, max_depth=9, min_child_weight=5, n_estimators=150, subsample=1.102841899659402; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5843072910452832, learning_rate=0.3206294818356601, max_depth=9, min_child_weight=5, n_estimators=150, subsample=1.102841899659402; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5843072910452832, learning_rate=0.3206294818356601, max_depth=9, min_child_weight=5, n_estimators=150, subsample=1.102841899659402; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5843072910452832, learning_rate=0.3206294818356601, max_depth=9, min_child_weight=5, n_estimators=150, subsample=1.102841899659402; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0680247633975366, learning_rate=0.576886782124989, max_depth=8, min_child_weight=1, n_estimators=383, subsample=0.9020316536967896; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0680247633975366, learning_rate=0.576886782124989, max_depth=8, min_child_weight=1, n_estimators=383, subsample=0.9020316536967896; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0680247633975366, learning_rate=0.576886782124989, max_depth=8, min_child_weight=1, n_estimators=383, subsample=0.9020316536967896; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0680247633975366, learning_rate=0.576886782124989, max_depth=8, min_child_weight=1, n_estimators=383, subsample=0.9020316536967896; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0680247633975366, learning_rate=0.576886782124989, max_depth=8, min_child_weight=1, n_estimators=383, subsample=0.9020316536967896; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2777508085647127, learning_rate=0.23811116094493318, max_depth=5, min_child_weight=4, n_estimators=134, subsample=0.9916986128756782; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2777508085647127, learning_rate=0.23811116094493318, max_depth=5, min_child_weight=4, n_estimators=134, subsample=0.9916986128756782; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2777508085647127, learning_rate=0.23811116094493318, max_depth=5, min_child_weight=4, n_estimators=134, subsample=0.9916986128756782; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2777508085647127, learning_rate=0.23811116094493318, max_depth=5, min_child_weight=4, n_estimators=134, subsample=0.9916986128756782; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2777508085647127, learning_rate=0.23811116094493318, max_depth=5, min_child_weight=4, n_estimators=134, subsample=0.9916986128756782; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5392433945789904, learning_rate=0.6967303064784046, max_depth=8, min_child_weight=5, n_estimators=145, subsample=1.1233779511984037; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5392433945789904, learning_rate=0.6967303064784046, max_depth=8, min_child_weight=5, n_estimators=145, subsample=1.1233779511984037; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5392433945789904, learning_rate=0.6967303064784046, max_depth=8, min_child_weight=5, n_estimators=145, subsample=1.1233779511984037; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5392433945789904, learning_rate=0.6967303064784046, max_depth=8, min_child_weight=5, n_estimators=145, subsample=1.1233779511984037; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5392433945789904, learning_rate=0.6967303064784046, max_depth=8, min_child_weight=5, n_estimators=145, subsample=1.1233779511984037; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8331428302299, learning_rate=0.10927396991732047, max_depth=7, min_child_weight=1, n_estimators=401, subsample=1.1699893371393026; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8331428302299, learning_rate=0.10927396991732047, max_depth=7, min_child_weight=1, n_estimators=401, subsample=1.1699893371393026; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8331428302299, learning_rate=0.10927396991732047, max_depth=7, min_child_weight=1, n_estimators=401, subsample=1.1699893371393026; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8331428302299, learning_rate=0.10927396991732047, max_depth=7, min_child_weight=1, n_estimators=401, subsample=1.1699893371393026; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8331428302299, learning_rate=0.10927396991732047, max_depth=7, min_child_weight=1, n_estimators=401, subsample=1.1699893371393026; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3672579793803274, learning_rate=0.611805673280416, max_depth=9, min_child_weight=5, n_estimators=260, subsample=0.5852298046406499; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3672579793803274, learning_rate=0.611805673280416, max_depth=9, min_child_weight=5, n_estimators=260, subsample=0.5852298046406499; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3672579793803274, learning_rate=0.611805673280416, max_depth=9, min_child_weight=5, n_estimators=260, subsample=0.5852298046406499; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3672579793803274, learning_rate=0.611805673280416, max_depth=9, min_child_weight=5, n_estimators=260, subsample=0.5852298046406499; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3672579793803274, learning_rate=0.611805673280416, max_depth=9, min_child_weight=5, n_estimators=260, subsample=0.5852298046406499; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6525434720174832, learning_rate=0.43408075747501007, max_depth=9, min_child_weight=2, n_estimators=422, subsample=0.8130550530804286; total time=10.1min\n",
      "[CV] END colsample_bytree=0.6525434720174832, learning_rate=0.43408075747501007, max_depth=9, min_child_weight=2, n_estimators=422, subsample=0.8130550530804286; total time= 9.9min\n",
      "[CV] END colsample_bytree=0.6525434720174832, learning_rate=0.43408075747501007, max_depth=9, min_child_weight=2, n_estimators=422, subsample=0.8130550530804286; total time= 9.8min\n",
      "[CV] END colsample_bytree=0.6525434720174832, learning_rate=0.43408075747501007, max_depth=9, min_child_weight=2, n_estimators=422, subsample=0.8130550530804286; total time= 9.8min\n",
      "[CV] END colsample_bytree=0.6525434720174832, learning_rate=0.43408075747501007, max_depth=9, min_child_weight=2, n_estimators=422, subsample=0.8130550530804286; total time= 9.8min\n",
      "[CV] END colsample_bytree=0.5874588443936917, learning_rate=0.46900433601950187, max_depth=8, min_child_weight=2, n_estimators=226, subsample=0.7664966871273631; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.5874588443936917, learning_rate=0.46900433601950187, max_depth=8, min_child_weight=2, n_estimators=226, subsample=0.7664966871273631; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.5874588443936917, learning_rate=0.46900433601950187, max_depth=8, min_child_weight=2, n_estimators=226, subsample=0.7664966871273631; total time= 4.3min\n",
      "[CV] END colsample_bytree=0.5874588443936917, learning_rate=0.46900433601950187, max_depth=8, min_child_weight=2, n_estimators=226, subsample=0.7664966871273631; total time= 4.3min\n",
      "[CV] END colsample_bytree=0.5874588443936917, learning_rate=0.46900433601950187, max_depth=8, min_child_weight=2, n_estimators=226, subsample=0.7664966871273631; total time= 4.3min\n",
      "[CV] END colsample_bytree=1.28963576473516, learning_rate=0.5444611706525226, max_depth=3, min_child_weight=1, n_estimators=398, subsample=0.9380198972191067; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.28963576473516, learning_rate=0.5444611706525226, max_depth=3, min_child_weight=1, n_estimators=398, subsample=0.9380198972191067; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.28963576473516, learning_rate=0.5444611706525226, max_depth=3, min_child_weight=1, n_estimators=398, subsample=0.9380198972191067; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.28963576473516, learning_rate=0.5444611706525226, max_depth=3, min_child_weight=1, n_estimators=398, subsample=0.9380198972191067; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.28963576473516, learning_rate=0.5444611706525226, max_depth=3, min_child_weight=1, n_estimators=398, subsample=0.9380198972191067; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.997537979217117, learning_rate=0.27790608618867907, max_depth=4, min_child_weight=3, n_estimators=405, subsample=1.0803650867220933; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.997537979217117, learning_rate=0.27790608618867907, max_depth=4, min_child_weight=3, n_estimators=405, subsample=1.0803650867220933; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.997537979217117, learning_rate=0.27790608618867907, max_depth=4, min_child_weight=3, n_estimators=405, subsample=1.0803650867220933; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.997537979217117, learning_rate=0.27790608618867907, max_depth=4, min_child_weight=3, n_estimators=405, subsample=1.0803650867220933; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.997537979217117, learning_rate=0.27790608618867907, max_depth=4, min_child_weight=3, n_estimators=405, subsample=1.0803650867220933; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3219164973008242, learning_rate=0.40680543931656266, max_depth=3, min_child_weight=4, n_estimators=272, subsample=0.474846558160838; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3219164973008242, learning_rate=0.40680543931656266, max_depth=3, min_child_weight=4, n_estimators=272, subsample=0.474846558160838; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3219164973008242, learning_rate=0.40680543931656266, max_depth=3, min_child_weight=4, n_estimators=272, subsample=0.474846558160838; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3219164973008242, learning_rate=0.40680543931656266, max_depth=3, min_child_weight=4, n_estimators=272, subsample=0.474846558160838; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3219164973008242, learning_rate=0.40680543931656266, max_depth=3, min_child_weight=4, n_estimators=272, subsample=0.474846558160838; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5638468252999349, learning_rate=0.338070296328333, max_depth=8, min_child_weight=4, n_estimators=470, subsample=0.6041956411663822; total time= 8.9min\n",
      "[CV] END colsample_bytree=0.5638468252999349, learning_rate=0.338070296328333, max_depth=8, min_child_weight=4, n_estimators=470, subsample=0.6041956411663822; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.5638468252999349, learning_rate=0.338070296328333, max_depth=8, min_child_weight=4, n_estimators=470, subsample=0.6041956411663822; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.5638468252999349, learning_rate=0.338070296328333, max_depth=8, min_child_weight=4, n_estimators=470, subsample=0.6041956411663822; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.5638468252999349, learning_rate=0.338070296328333, max_depth=8, min_child_weight=4, n_estimators=470, subsample=0.6041956411663822; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.8380246573759496, learning_rate=0.1563891639045214, max_depth=9, min_child_weight=3, n_estimators=252, subsample=0.4395374550549698; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.8380246573759496, learning_rate=0.1563891639045214, max_depth=9, min_child_weight=3, n_estimators=252, subsample=0.4395374550549698; total time= 7.3min\n",
      "[CV] END colsample_bytree=0.8380246573759496, learning_rate=0.1563891639045214, max_depth=9, min_child_weight=3, n_estimators=252, subsample=0.4395374550549698; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.8380246573759496, learning_rate=0.1563891639045214, max_depth=9, min_child_weight=3, n_estimators=252, subsample=0.4395374550549698; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.8380246573759496, learning_rate=0.1563891639045214, max_depth=9, min_child_weight=3, n_estimators=252, subsample=0.4395374550549698; total time= 7.2min\n",
      "[CV] END colsample_bytree=1.383656799479478, learning_rate=0.603360101241618, max_depth=4, min_child_weight=1, n_estimators=279, subsample=0.33495126098648087; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.383656799479478, learning_rate=0.603360101241618, max_depth=4, min_child_weight=1, n_estimators=279, subsample=0.33495126098648087; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.383656799479478, learning_rate=0.603360101241618, max_depth=4, min_child_weight=1, n_estimators=279, subsample=0.33495126098648087; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.383656799479478, learning_rate=0.603360101241618, max_depth=4, min_child_weight=1, n_estimators=279, subsample=0.33495126098648087; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.383656799479478, learning_rate=0.603360101241618, max_depth=4, min_child_weight=1, n_estimators=279, subsample=0.33495126098648087; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7729389632059005, learning_rate=0.42224945631799327, max_depth=7, min_child_weight=1, n_estimators=363, subsample=0.9929941977887498; total time= 7.4min\n",
      "[CV] END colsample_bytree=0.7729389632059005, learning_rate=0.42224945631799327, max_depth=7, min_child_weight=1, n_estimators=363, subsample=0.9929941977887498; total time= 7.3min\n",
      "[CV] END colsample_bytree=0.7729389632059005, learning_rate=0.42224945631799327, max_depth=7, min_child_weight=1, n_estimators=363, subsample=0.9929941977887498; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.7729389632059005, learning_rate=0.42224945631799327, max_depth=7, min_child_weight=1, n_estimators=363, subsample=0.9929941977887498; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.7729389632059005, learning_rate=0.42224945631799327, max_depth=7, min_child_weight=1, n_estimators=363, subsample=0.9929941977887498; total time= 7.2min\n",
      "[CV] END colsample_bytree=0.6942389247471589, learning_rate=0.4737342854914002, max_depth=6, min_child_weight=5, n_estimators=471, subsample=0.6702185145510107; total time= 7.9min\n",
      "[CV] END colsample_bytree=0.6942389247471589, learning_rate=0.4737342854914002, max_depth=6, min_child_weight=5, n_estimators=471, subsample=0.6702185145510107; total time= 7.8min\n",
      "[CV] END colsample_bytree=0.6942389247471589, learning_rate=0.4737342854914002, max_depth=6, min_child_weight=5, n_estimators=471, subsample=0.6702185145510107; total time= 7.7min\n",
      "[CV] END colsample_bytree=0.6942389247471589, learning_rate=0.4737342854914002, max_depth=6, min_child_weight=5, n_estimators=471, subsample=0.6702185145510107; total time= 7.7min\n",
      "[CV] END colsample_bytree=0.6942389247471589, learning_rate=0.4737342854914002, max_depth=6, min_child_weight=5, n_estimators=471, subsample=0.6702185145510107; total time= 7.8min\n",
      "[CV] END colsample_bytree=1.1295609896904746, learning_rate=0.18301185545068083, max_depth=7, min_child_weight=2, n_estimators=223, subsample=0.943135593761957; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1295609896904746, learning_rate=0.18301185545068083, max_depth=7, min_child_weight=2, n_estimators=223, subsample=0.943135593761957; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1295609896904746, learning_rate=0.18301185545068083, max_depth=7, min_child_weight=2, n_estimators=223, subsample=0.943135593761957; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1295609896904746, learning_rate=0.18301185545068083, max_depth=7, min_child_weight=2, n_estimators=223, subsample=0.943135593761957; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1295609896904746, learning_rate=0.18301185545068083, max_depth=7, min_child_weight=2, n_estimators=223, subsample=0.943135593761957; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5369607650910883, learning_rate=0.3392925408668767, max_depth=5, min_child_weight=4, n_estimators=157, subsample=0.37061074320803933; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5369607650910883, learning_rate=0.3392925408668767, max_depth=5, min_child_weight=4, n_estimators=157, subsample=0.37061074320803933; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5369607650910883, learning_rate=0.3392925408668767, max_depth=5, min_child_weight=4, n_estimators=157, subsample=0.37061074320803933; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5369607650910883, learning_rate=0.3392925408668767, max_depth=5, min_child_weight=4, n_estimators=157, subsample=0.37061074320803933; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5369607650910883, learning_rate=0.3392925408668767, max_depth=5, min_child_weight=4, n_estimators=157, subsample=0.37061074320803933; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.5228156690739117, learning_rate=0.677589048806755, max_depth=9, min_child_weight=1, n_estimators=495, subsample=0.6680576499728429; total time=10.1min\n",
      "[CV] END colsample_bytree=0.5228156690739117, learning_rate=0.677589048806755, max_depth=9, min_child_weight=1, n_estimators=495, subsample=0.6680576499728429; total time= 9.9min\n",
      "[CV] END colsample_bytree=0.5228156690739117, learning_rate=0.677589048806755, max_depth=9, min_child_weight=1, n_estimators=495, subsample=0.6680576499728429; total time= 9.9min\n",
      "[CV] END colsample_bytree=0.5228156690739117, learning_rate=0.677589048806755, max_depth=9, min_child_weight=1, n_estimators=495, subsample=0.6680576499728429; total time= 9.9min\n",
      "[CV] END colsample_bytree=0.5228156690739117, learning_rate=0.677589048806755, max_depth=9, min_child_weight=1, n_estimators=495, subsample=0.6680576499728429; total time= 9.9min\n",
      "[CV] END colsample_bytree=0.6559648880637612, learning_rate=0.19386222560265165, max_depth=4, min_child_weight=1, n_estimators=336, subsample=0.5519405072513486; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.6559648880637612, learning_rate=0.19386222560265165, max_depth=4, min_child_weight=1, n_estimators=336, subsample=0.5519405072513486; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.6559648880637612, learning_rate=0.19386222560265165, max_depth=4, min_child_weight=1, n_estimators=336, subsample=0.5519405072513486; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.6559648880637612, learning_rate=0.19386222560265165, max_depth=4, min_child_weight=1, n_estimators=336, subsample=0.5519405072513486; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.6559648880637612, learning_rate=0.19386222560265165, max_depth=4, min_child_weight=1, n_estimators=336, subsample=0.5519405072513486; total time= 3.7min\n",
      "[CV] END colsample_bytree=1.3593787525968746, learning_rate=0.5427381500174611, max_depth=9, min_child_weight=5, n_estimators=377, subsample=0.9570353849056368; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3593787525968746, learning_rate=0.5427381500174611, max_depth=9, min_child_weight=5, n_estimators=377, subsample=0.9570353849056368; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3593787525968746, learning_rate=0.5427381500174611, max_depth=9, min_child_weight=5, n_estimators=377, subsample=0.9570353849056368; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3593787525968746, learning_rate=0.5427381500174611, max_depth=9, min_child_weight=5, n_estimators=377, subsample=0.9570353849056368; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3593787525968746, learning_rate=0.5427381500174611, max_depth=9, min_child_weight=5, n_estimators=377, subsample=0.9570353849056368; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5429445149224839, learning_rate=0.4396223262964458, max_depth=5, min_child_weight=5, n_estimators=185, subsample=0.31295413976678027; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5429445149224839, learning_rate=0.4396223262964458, max_depth=5, min_child_weight=5, n_estimators=185, subsample=0.31295413976678027; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5429445149224839, learning_rate=0.4396223262964458, max_depth=5, min_child_weight=5, n_estimators=185, subsample=0.31295413976678027; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5429445149224839, learning_rate=0.4396223262964458, max_depth=5, min_child_weight=5, n_estimators=185, subsample=0.31295413976678027; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5429445149224839, learning_rate=0.4396223262964458, max_depth=5, min_child_weight=5, n_estimators=185, subsample=0.31295413976678027; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.6044653764562247, learning_rate=0.12760158521305165, max_depth=3, min_child_weight=4, n_estimators=303, subsample=0.3154449916485752; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.6044653764562247, learning_rate=0.12760158521305165, max_depth=3, min_child_weight=4, n_estimators=303, subsample=0.3154449916485752; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.6044653764562247, learning_rate=0.12760158521305165, max_depth=3, min_child_weight=4, n_estimators=303, subsample=0.3154449916485752; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.6044653764562247, learning_rate=0.12760158521305165, max_depth=3, min_child_weight=4, n_estimators=303, subsample=0.3154449916485752; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.6044653764562247, learning_rate=0.12760158521305165, max_depth=3, min_child_weight=4, n_estimators=303, subsample=0.3154449916485752; total time= 2.1min\n",
      "[CV] END colsample_bytree=1.1870279807035198, learning_rate=0.5841477862304677, max_depth=6, min_child_weight=1, n_estimators=353, subsample=0.6904664843141757; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1870279807035198, learning_rate=0.5841477862304677, max_depth=6, min_child_weight=1, n_estimators=353, subsample=0.6904664843141757; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1870279807035198, learning_rate=0.5841477862304677, max_depth=6, min_child_weight=1, n_estimators=353, subsample=0.6904664843141757; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1870279807035198, learning_rate=0.5841477862304677, max_depth=6, min_child_weight=1, n_estimators=353, subsample=0.6904664843141757; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1870279807035198, learning_rate=0.5841477862304677, max_depth=6, min_child_weight=1, n_estimators=353, subsample=0.6904664843141757; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8586542609576361, learning_rate=0.4695100588313299, max_depth=7, min_child_weight=4, n_estimators=389, subsample=0.5348042610075425; total time= 9.2min\n",
      "[CV] END colsample_bytree=0.8586542609576361, learning_rate=0.4695100588313299, max_depth=7, min_child_weight=4, n_estimators=389, subsample=0.5348042610075425; total time= 9.2min\n",
      "[CV] END colsample_bytree=0.8586542609576361, learning_rate=0.4695100588313299, max_depth=7, min_child_weight=4, n_estimators=389, subsample=0.5348042610075425; total time= 9.1min\n",
      "[CV] END colsample_bytree=0.8586542609576361, learning_rate=0.4695100588313299, max_depth=7, min_child_weight=4, n_estimators=389, subsample=0.5348042610075425; total time= 9.5min\n",
      "[CV] END colsample_bytree=0.8586542609576361, learning_rate=0.4695100588313299, max_depth=7, min_child_weight=4, n_estimators=389, subsample=0.5348042610075425; total time= 9.5min\n",
      "[CV] END colsample_bytree=0.5137740862613462, learning_rate=0.6600617848476897, max_depth=3, min_child_weight=5, n_estimators=103, subsample=0.8542660479509225; total time=  45.8s\n",
      "[CV] END colsample_bytree=0.5137740862613462, learning_rate=0.6600617848476897, max_depth=3, min_child_weight=5, n_estimators=103, subsample=0.8542660479509225; total time=  44.7s\n",
      "[CV] END colsample_bytree=0.5137740862613462, learning_rate=0.6600617848476897, max_depth=3, min_child_weight=5, n_estimators=103, subsample=0.8542660479509225; total time=  44.7s\n",
      "[CV] END colsample_bytree=0.5137740862613462, learning_rate=0.6600617848476897, max_depth=3, min_child_weight=5, n_estimators=103, subsample=0.8542660479509225; total time=  44.6s\n",
      "[CV] END colsample_bytree=0.5137740862613462, learning_rate=0.6600617848476897, max_depth=3, min_child_weight=5, n_estimators=103, subsample=0.8542660479509225; total time=  47.7s\n",
      "[CV] END colsample_bytree=1.3495024441046815, learning_rate=0.6665509582751004, max_depth=6, min_child_weight=3, n_estimators=439, subsample=0.8179267600882911; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.3495024441046815, learning_rate=0.6665509582751004, max_depth=6, min_child_weight=3, n_estimators=439, subsample=0.8179267600882911; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.3495024441046815, learning_rate=0.6665509582751004, max_depth=6, min_child_weight=3, n_estimators=439, subsample=0.8179267600882911; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3495024441046815, learning_rate=0.6665509582751004, max_depth=6, min_child_weight=3, n_estimators=439, subsample=0.8179267600882911; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3495024441046815, learning_rate=0.6665509582751004, max_depth=6, min_child_weight=3, n_estimators=439, subsample=0.8179267600882911; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8493529335858697, learning_rate=0.48597293106541195, max_depth=3, min_child_weight=5, n_estimators=278, subsample=1.03857552816956; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8493529335858697, learning_rate=0.48597293106541195, max_depth=3, min_child_weight=5, n_estimators=278, subsample=1.03857552816956; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8493529335858697, learning_rate=0.48597293106541195, max_depth=3, min_child_weight=5, n_estimators=278, subsample=1.03857552816956; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8493529335858697, learning_rate=0.48597293106541195, max_depth=3, min_child_weight=5, n_estimators=278, subsample=1.03857552816956; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8493529335858697, learning_rate=0.48597293106541195, max_depth=3, min_child_weight=5, n_estimators=278, subsample=1.03857552816956; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0633457030914155, learning_rate=0.5922561062627608, max_depth=4, min_child_weight=3, n_estimators=143, subsample=0.5465650145890204; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0633457030914155, learning_rate=0.5922561062627608, max_depth=4, min_child_weight=3, n_estimators=143, subsample=0.5465650145890204; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0633457030914155, learning_rate=0.5922561062627608, max_depth=4, min_child_weight=3, n_estimators=143, subsample=0.5465650145890204; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0633457030914155, learning_rate=0.5922561062627608, max_depth=4, min_child_weight=3, n_estimators=143, subsample=0.5465650145890204; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0633457030914155, learning_rate=0.5922561062627608, max_depth=4, min_child_weight=3, n_estimators=143, subsample=0.5465650145890204; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6931302077375368, learning_rate=0.3263554499367855, max_depth=7, min_child_weight=3, n_estimators=341, subsample=0.9147060960747211; total time= 6.9min\n",
      "[CV] END colsample_bytree=0.6931302077375368, learning_rate=0.3263554499367855, max_depth=7, min_child_weight=3, n_estimators=341, subsample=0.9147060960747211; total time= 7.7min\n",
      "[CV] END colsample_bytree=0.6931302077375368, learning_rate=0.3263554499367855, max_depth=7, min_child_weight=3, n_estimators=341, subsample=0.9147060960747211; total time= 8.3min\n",
      "[CV] END colsample_bytree=0.6931302077375368, learning_rate=0.3263554499367855, max_depth=7, min_child_weight=3, n_estimators=341, subsample=0.9147060960747211; total time= 6.8min\n",
      "[CV] END colsample_bytree=0.6931302077375368, learning_rate=0.3263554499367855, max_depth=7, min_child_weight=3, n_estimators=341, subsample=0.9147060960747211; total time= 6.3min\n",
      "[CV] END colsample_bytree=0.5640697836142061, learning_rate=0.29138537817625676, max_depth=4, min_child_weight=2, n_estimators=189, subsample=0.606562112517816; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5640697836142061, learning_rate=0.29138537817625676, max_depth=4, min_child_weight=2, n_estimators=189, subsample=0.606562112517816; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5640697836142061, learning_rate=0.29138537817625676, max_depth=4, min_child_weight=2, n_estimators=189, subsample=0.606562112517816; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5640697836142061, learning_rate=0.29138537817625676, max_depth=4, min_child_weight=2, n_estimators=189, subsample=0.606562112517816; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.5640697836142061, learning_rate=0.29138537817625676, max_depth=4, min_child_weight=2, n_estimators=189, subsample=0.606562112517816; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.7346250754123128, learning_rate=0.39762247257604366, max_depth=4, min_child_weight=5, n_estimators=213, subsample=0.8660485621018956; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.7346250754123128, learning_rate=0.39762247257604366, max_depth=4, min_child_weight=5, n_estimators=213, subsample=0.8660485621018956; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.7346250754123128, learning_rate=0.39762247257604366, max_depth=4, min_child_weight=5, n_estimators=213, subsample=0.8660485621018956; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.7346250754123128, learning_rate=0.39762247257604366, max_depth=4, min_child_weight=5, n_estimators=213, subsample=0.8660485621018956; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.7346250754123128, learning_rate=0.39762247257604366, max_depth=4, min_child_weight=5, n_estimators=213, subsample=0.8660485621018956; total time= 2.4min\n",
      "[CV] END colsample_bytree=1.2897248121743476, learning_rate=0.5410426262823315, max_depth=7, min_child_weight=5, n_estimators=348, subsample=0.7931746949232785; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2897248121743476, learning_rate=0.5410426262823315, max_depth=7, min_child_weight=5, n_estimators=348, subsample=0.7931746949232785; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2897248121743476, learning_rate=0.5410426262823315, max_depth=7, min_child_weight=5, n_estimators=348, subsample=0.7931746949232785; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2897248121743476, learning_rate=0.5410426262823315, max_depth=7, min_child_weight=5, n_estimators=348, subsample=0.7931746949232785; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.2897248121743476, learning_rate=0.5410426262823315, max_depth=7, min_child_weight=5, n_estimators=348, subsample=0.7931746949232785; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8811238480773067, learning_rate=0.44111217024997496, max_depth=5, min_child_weight=1, n_estimators=198, subsample=0.6713559092202839; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8811238480773067, learning_rate=0.44111217024997496, max_depth=5, min_child_weight=1, n_estimators=198, subsample=0.6713559092202839; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.8811238480773067, learning_rate=0.44111217024997496, max_depth=5, min_child_weight=1, n_estimators=198, subsample=0.6713559092202839; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.8811238480773067, learning_rate=0.44111217024997496, max_depth=5, min_child_weight=1, n_estimators=198, subsample=0.6713559092202839; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8811238480773067, learning_rate=0.44111217024997496, max_depth=5, min_child_weight=1, n_estimators=198, subsample=0.6713559092202839; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8348162772135048, learning_rate=0.5658477764451981, max_depth=9, min_child_weight=5, n_estimators=367, subsample=0.6860946246375166; total time=11.6min\n",
      "[CV] END colsample_bytree=0.8348162772135048, learning_rate=0.5658477764451981, max_depth=9, min_child_weight=5, n_estimators=367, subsample=0.6860946246375166; total time=11.3min\n",
      "[CV] END colsample_bytree=0.8348162772135048, learning_rate=0.5658477764451981, max_depth=9, min_child_weight=5, n_estimators=367, subsample=0.6860946246375166; total time=11.2min\n",
      "[CV] END colsample_bytree=0.8348162772135048, learning_rate=0.5658477764451981, max_depth=9, min_child_weight=5, n_estimators=367, subsample=0.6860946246375166; total time=11.2min\n",
      "[CV] END colsample_bytree=0.8348162772135048, learning_rate=0.5658477764451981, max_depth=9, min_child_weight=5, n_estimators=367, subsample=0.6860946246375166; total time=11.2min\n",
      "[CV] END colsample_bytree=1.1757839610123475, learning_rate=0.5527257244508094, max_depth=3, min_child_weight=1, n_estimators=468, subsample=0.7547271352030714; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1757839610123475, learning_rate=0.5527257244508094, max_depth=3, min_child_weight=1, n_estimators=468, subsample=0.7547271352030714; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.1757839610123475, learning_rate=0.5527257244508094, max_depth=3, min_child_weight=1, n_estimators=468, subsample=0.7547271352030714; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1757839610123475, learning_rate=0.5527257244508094, max_depth=3, min_child_weight=1, n_estimators=468, subsample=0.7547271352030714; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.1757839610123475, learning_rate=0.5527257244508094, max_depth=3, min_child_weight=1, n_estimators=468, subsample=0.7547271352030714; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2438117194969673, learning_rate=0.29202976061836705, max_depth=5, min_child_weight=3, n_estimators=276, subsample=0.348136767072632; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2438117194969673, learning_rate=0.29202976061836705, max_depth=5, min_child_weight=3, n_estimators=276, subsample=0.348136767072632; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2438117194969673, learning_rate=0.29202976061836705, max_depth=5, min_child_weight=3, n_estimators=276, subsample=0.348136767072632; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2438117194969673, learning_rate=0.29202976061836705, max_depth=5, min_child_weight=3, n_estimators=276, subsample=0.348136767072632; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2438117194969673, learning_rate=0.29202976061836705, max_depth=5, min_child_weight=3, n_estimators=276, subsample=0.348136767072632; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3626873471948784, learning_rate=0.6082858864573538, max_depth=3, min_child_weight=4, n_estimators=305, subsample=0.9090929139818729; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3626873471948784, learning_rate=0.6082858864573538, max_depth=3, min_child_weight=4, n_estimators=305, subsample=0.9090929139818729; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3626873471948784, learning_rate=0.6082858864573538, max_depth=3, min_child_weight=4, n_estimators=305, subsample=0.9090929139818729; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3626873471948784, learning_rate=0.6082858864573538, max_depth=3, min_child_weight=4, n_estimators=305, subsample=0.9090929139818729; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3626873471948784, learning_rate=0.6082858864573538, max_depth=3, min_child_weight=4, n_estimators=305, subsample=0.9090929139818729; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9342688546783782, learning_rate=0.395815394663083, max_depth=7, min_child_weight=5, n_estimators=198, subsample=0.842196833311007; total time= 5.1min\n",
      "[CV] END colsample_bytree=0.9342688546783782, learning_rate=0.395815394663083, max_depth=7, min_child_weight=5, n_estimators=198, subsample=0.842196833311007; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.9342688546783782, learning_rate=0.395815394663083, max_depth=7, min_child_weight=5, n_estimators=198, subsample=0.842196833311007; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.9342688546783782, learning_rate=0.395815394663083, max_depth=7, min_child_weight=5, n_estimators=198, subsample=0.842196833311007; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.9342688546783782, learning_rate=0.395815394663083, max_depth=7, min_child_weight=5, n_estimators=198, subsample=0.842196833311007; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.9983327471112207, learning_rate=0.22763673701453738, max_depth=7, min_child_weight=1, n_estimators=138, subsample=0.3820854927438213; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9983327471112207, learning_rate=0.22763673701453738, max_depth=7, min_child_weight=1, n_estimators=138, subsample=0.3820854927438213; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9983327471112207, learning_rate=0.22763673701453738, max_depth=7, min_child_weight=1, n_estimators=138, subsample=0.3820854927438213; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9983327471112207, learning_rate=0.22763673701453738, max_depth=7, min_child_weight=1, n_estimators=138, subsample=0.3820854927438213; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9983327471112207, learning_rate=0.22763673701453738, max_depth=7, min_child_weight=1, n_estimators=138, subsample=0.3820854927438213; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9449782742323234, learning_rate=0.13453525600998656, max_depth=9, min_child_weight=2, n_estimators=232, subsample=0.963332001111908; total time= 7.8min\n",
      "[CV] END colsample_bytree=0.9449782742323234, learning_rate=0.13453525600998656, max_depth=9, min_child_weight=2, n_estimators=232, subsample=0.963332001111908; total time= 7.6min\n",
      "[CV] END colsample_bytree=0.9449782742323234, learning_rate=0.13453525600998656, max_depth=9, min_child_weight=2, n_estimators=232, subsample=0.963332001111908; total time= 7.5min\n",
      "[CV] END colsample_bytree=0.9449782742323234, learning_rate=0.13453525600998656, max_depth=9, min_child_weight=2, n_estimators=232, subsample=0.963332001111908; total time= 7.5min\n",
      "[CV] END colsample_bytree=0.9449782742323234, learning_rate=0.13453525600998656, max_depth=9, min_child_weight=2, n_estimators=232, subsample=0.963332001111908; total time= 7.5min\n",
      "[CV] END colsample_bytree=0.9913241931484901, learning_rate=0.5234988903272167, max_depth=9, min_child_weight=4, n_estimators=108, subsample=0.985359568545725; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.9913241931484901, learning_rate=0.5234988903272167, max_depth=9, min_child_weight=4, n_estimators=108, subsample=0.985359568545725; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.9913241931484901, learning_rate=0.5234988903272167, max_depth=9, min_child_weight=4, n_estimators=108, subsample=0.985359568545725; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.9913241931484901, learning_rate=0.5234988903272167, max_depth=9, min_child_weight=4, n_estimators=108, subsample=0.985359568545725; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9913241931484901, learning_rate=0.5234988903272167, max_depth=9, min_child_weight=4, n_estimators=108, subsample=0.985359568545725; total time= 3.5min\n",
      "[CV] END colsample_bytree=1.056396256984635, learning_rate=0.16067360567367414, max_depth=9, min_child_weight=5, n_estimators=267, subsample=0.3654867057277742; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.056396256984635, learning_rate=0.16067360567367414, max_depth=9, min_child_weight=5, n_estimators=267, subsample=0.3654867057277742; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.056396256984635, learning_rate=0.16067360567367414, max_depth=9, min_child_weight=5, n_estimators=267, subsample=0.3654867057277742; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.056396256984635, learning_rate=0.16067360567367414, max_depth=9, min_child_weight=5, n_estimators=267, subsample=0.3654867057277742; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.056396256984635, learning_rate=0.16067360567367414, max_depth=9, min_child_weight=5, n_estimators=267, subsample=0.3654867057277742; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2396740533613206, learning_rate=0.5237453362938977, max_depth=7, min_child_weight=5, n_estimators=264, subsample=0.509905265182075; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2396740533613206, learning_rate=0.5237453362938977, max_depth=7, min_child_weight=5, n_estimators=264, subsample=0.509905265182075; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2396740533613206, learning_rate=0.5237453362938977, max_depth=7, min_child_weight=5, n_estimators=264, subsample=0.509905265182075; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2396740533613206, learning_rate=0.5237453362938977, max_depth=7, min_child_weight=5, n_estimators=264, subsample=0.509905265182075; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.2396740533613206, learning_rate=0.5237453362938977, max_depth=7, min_child_weight=5, n_estimators=264, subsample=0.509905265182075; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0231748755041041, learning_rate=0.6178831131934023, max_depth=8, min_child_weight=4, n_estimators=244, subsample=1.1525237196454727; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0231748755041041, learning_rate=0.6178831131934023, max_depth=8, min_child_weight=4, n_estimators=244, subsample=1.1525237196454727; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0231748755041041, learning_rate=0.6178831131934023, max_depth=8, min_child_weight=4, n_estimators=244, subsample=1.1525237196454727; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0231748755041041, learning_rate=0.6178831131934023, max_depth=8, min_child_weight=4, n_estimators=244, subsample=1.1525237196454727; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0231748755041041, learning_rate=0.6178831131934023, max_depth=8, min_child_weight=4, n_estimators=244, subsample=1.1525237196454727; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3874009574405837, learning_rate=0.552026911155365, max_depth=8, min_child_weight=4, n_estimators=374, subsample=0.9994322243346931; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3874009574405837, learning_rate=0.552026911155365, max_depth=8, min_child_weight=4, n_estimators=374, subsample=0.9994322243346931; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3874009574405837, learning_rate=0.552026911155365, max_depth=8, min_child_weight=4, n_estimators=374, subsample=0.9994322243346931; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3874009574405837, learning_rate=0.552026911155365, max_depth=8, min_child_weight=4, n_estimators=374, subsample=0.9994322243346931; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3874009574405837, learning_rate=0.552026911155365, max_depth=8, min_child_weight=4, n_estimators=374, subsample=0.9994322243346931; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0025638247622246, learning_rate=0.3545332055481858, max_depth=4, min_child_weight=3, n_estimators=138, subsample=0.6910066600394442; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0025638247622246, learning_rate=0.3545332055481858, max_depth=4, min_child_weight=3, n_estimators=138, subsample=0.6910066600394442; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0025638247622246, learning_rate=0.3545332055481858, max_depth=4, min_child_weight=3, n_estimators=138, subsample=0.6910066600394442; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0025638247622246, learning_rate=0.3545332055481858, max_depth=4, min_child_weight=3, n_estimators=138, subsample=0.6910066600394442; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0025638247622246, learning_rate=0.3545332055481858, max_depth=4, min_child_weight=3, n_estimators=138, subsample=0.6910066600394442; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7283139564858249, learning_rate=0.34312125206885025, max_depth=8, min_child_weight=2, n_estimators=247, subsample=0.4069361246412647; total time= 5.5min\n",
      "[CV] END colsample_bytree=0.7283139564858249, learning_rate=0.34312125206885025, max_depth=8, min_child_weight=2, n_estimators=247, subsample=0.4069361246412647; total time= 5.5min\n",
      "[CV] END colsample_bytree=0.7283139564858249, learning_rate=0.34312125206885025, max_depth=8, min_child_weight=2, n_estimators=247, subsample=0.4069361246412647; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.7283139564858249, learning_rate=0.34312125206885025, max_depth=8, min_child_weight=2, n_estimators=247, subsample=0.4069361246412647; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.7283139564858249, learning_rate=0.34312125206885025, max_depth=8, min_child_weight=2, n_estimators=247, subsample=0.4069361246412647; total time= 5.4min\n",
      "[CV] END colsample_bytree=0.6057736220993943, learning_rate=0.4895261812696381, max_depth=3, min_child_weight=3, n_estimators=447, subsample=1.1659552936270878; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6057736220993943, learning_rate=0.4895261812696381, max_depth=3, min_child_weight=3, n_estimators=447, subsample=1.1659552936270878; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6057736220993943, learning_rate=0.4895261812696381, max_depth=3, min_child_weight=3, n_estimators=447, subsample=1.1659552936270878; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6057736220993943, learning_rate=0.4895261812696381, max_depth=3, min_child_weight=3, n_estimators=447, subsample=1.1659552936270878; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6057736220993943, learning_rate=0.4895261812696381, max_depth=3, min_child_weight=3, n_estimators=447, subsample=1.1659552936270878; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8373835215713337, learning_rate=0.2714272517691164, max_depth=3, min_child_weight=5, n_estimators=233, subsample=1.0218983241240607; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8373835215713337, learning_rate=0.2714272517691164, max_depth=3, min_child_weight=5, n_estimators=233, subsample=1.0218983241240607; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8373835215713337, learning_rate=0.2714272517691164, max_depth=3, min_child_weight=5, n_estimators=233, subsample=1.0218983241240607; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8373835215713337, learning_rate=0.2714272517691164, max_depth=3, min_child_weight=5, n_estimators=233, subsample=1.0218983241240607; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8373835215713337, learning_rate=0.2714272517691164, max_depth=3, min_child_weight=5, n_estimators=233, subsample=1.0218983241240607; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3801106018788438, learning_rate=0.4336030231855508, max_depth=9, min_child_weight=5, n_estimators=179, subsample=0.7749309981776699; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3801106018788438, learning_rate=0.4336030231855508, max_depth=9, min_child_weight=5, n_estimators=179, subsample=0.7749309981776699; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3801106018788438, learning_rate=0.4336030231855508, max_depth=9, min_child_weight=5, n_estimators=179, subsample=0.7749309981776699; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3801106018788438, learning_rate=0.4336030231855508, max_depth=9, min_child_weight=5, n_estimators=179, subsample=0.7749309981776699; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3801106018788438, learning_rate=0.4336030231855508, max_depth=9, min_child_weight=5, n_estimators=179, subsample=0.7749309981776699; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3936683165073704, learning_rate=0.14427793884123932, max_depth=5, min_child_weight=3, n_estimators=119, subsample=0.3678910923807923; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3936683165073704, learning_rate=0.14427793884123932, max_depth=5, min_child_weight=3, n_estimators=119, subsample=0.3678910923807923; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3936683165073704, learning_rate=0.14427793884123932, max_depth=5, min_child_weight=3, n_estimators=119, subsample=0.3678910923807923; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3936683165073704, learning_rate=0.14427793884123932, max_depth=5, min_child_weight=3, n_estimators=119, subsample=0.3678910923807923; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3936683165073704, learning_rate=0.14427793884123932, max_depth=5, min_child_weight=3, n_estimators=119, subsample=0.3678910923807923; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6495938887183277, learning_rate=0.23008546395189472, max_depth=9, min_child_weight=1, n_estimators=472, subsample=0.9272325502774332; total time=11.0min\n",
      "[CV] END colsample_bytree=0.6495938887183277, learning_rate=0.23008546395189472, max_depth=9, min_child_weight=1, n_estimators=472, subsample=0.9272325502774332; total time=10.7min\n",
      "[CV] END colsample_bytree=0.6495938887183277, learning_rate=0.23008546395189472, max_depth=9, min_child_weight=1, n_estimators=472, subsample=0.9272325502774332; total time=10.6min\n",
      "[CV] END colsample_bytree=0.6495938887183277, learning_rate=0.23008546395189472, max_depth=9, min_child_weight=1, n_estimators=472, subsample=0.9272325502774332; total time=10.8min\n",
      "[CV] END colsample_bytree=0.6495938887183277, learning_rate=0.23008546395189472, max_depth=9, min_child_weight=1, n_estimators=472, subsample=0.9272325502774332; total time=11.2min\n",
      "[CV] END colsample_bytree=0.8457816482412979, learning_rate=0.5422604235058115, max_depth=5, min_child_weight=4, n_estimators=429, subsample=1.155370335668903; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8457816482412979, learning_rate=0.5422604235058115, max_depth=5, min_child_weight=4, n_estimators=429, subsample=1.155370335668903; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8457816482412979, learning_rate=0.5422604235058115, max_depth=5, min_child_weight=4, n_estimators=429, subsample=1.155370335668903; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8457816482412979, learning_rate=0.5422604235058115, max_depth=5, min_child_weight=4, n_estimators=429, subsample=1.155370335668903; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8457816482412979, learning_rate=0.5422604235058115, max_depth=5, min_child_weight=4, n_estimators=429, subsample=1.155370335668903; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.3012374055018245, learning_rate=0.3733940516714278, max_depth=6, min_child_weight=5, n_estimators=107, subsample=0.452711913506009; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3012374055018245, learning_rate=0.3733940516714278, max_depth=6, min_child_weight=5, n_estimators=107, subsample=0.452711913506009; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3012374055018245, learning_rate=0.3733940516714278, max_depth=6, min_child_weight=5, n_estimators=107, subsample=0.452711913506009; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3012374055018245, learning_rate=0.3733940516714278, max_depth=6, min_child_weight=5, n_estimators=107, subsample=0.452711913506009; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3012374055018245, learning_rate=0.3733940516714278, max_depth=6, min_child_weight=5, n_estimators=107, subsample=0.452711913506009; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0821635255018514, learning_rate=0.33296103039392333, max_depth=6, min_child_weight=2, n_estimators=127, subsample=0.3699611732684863; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0821635255018514, learning_rate=0.33296103039392333, max_depth=6, min_child_weight=2, n_estimators=127, subsample=0.3699611732684863; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0821635255018514, learning_rate=0.33296103039392333, max_depth=6, min_child_weight=2, n_estimators=127, subsample=0.3699611732684863; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0821635255018514, learning_rate=0.33296103039392333, max_depth=6, min_child_weight=2, n_estimators=127, subsample=0.3699611732684863; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0821635255018514, learning_rate=0.33296103039392333, max_depth=6, min_child_weight=2, n_estimators=127, subsample=0.3699611732684863; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3769553268995498, learning_rate=0.6917264466877617, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.578574854657695; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3769553268995498, learning_rate=0.6917264466877617, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.578574854657695; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3769553268995498, learning_rate=0.6917264466877617, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.578574854657695; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3769553268995498, learning_rate=0.6917264466877617, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.578574854657695; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.3769553268995498, learning_rate=0.6917264466877617, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.578574854657695; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "265 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19299 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05573 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05067 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20666 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.27395 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00696 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.37263 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21116 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26503 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00515 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12596 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09242 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06192 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11615 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.3746 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12623 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.25394 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12621 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.39663 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29899 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10284 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06802 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.27775 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12338 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16999 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36726 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.28964 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08037 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.32192 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38366 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12956 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35938 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18703 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.3495 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03858 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06335 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.28972 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17578 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.24381 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36269 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0564 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.23967 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02317 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.3874 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00256 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16596 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0219 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38011 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.39367 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15537 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.30124 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08216 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/home/analyst/.local/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.37696 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/analyst/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.85958501 0.86258636        nan        nan        nan        nan\n",
      "        nan        nan 0.86193558 0.84612387        nan 0.85945874\n",
      " 0.86031349 0.85971796 0.85884499        nan        nan 0.86205031\n",
      "        nan 0.86213348        nan        nan        nan        nan\n",
      " 0.8623672  0.85233054 0.84637216        nan 0.85462222 0.86198354\n",
      " 0.83960941 0.85788825 0.85755254        nan 0.8601253         nan\n",
      "        nan        nan 0.86233321        nan 0.86295242 0.86116946\n",
      " 0.86155373        nan        nan        nan        nan        nan\n",
      "        nan 0.85110426 0.85649078        nan        nan        nan\n",
      " 0.85568763 0.86027889        nan 0.85881464 0.85801331        nan\n",
      " 0.86168789 0.83411726 0.86253597        nan 0.86065709 0.85896033\n",
      "        nan 0.85441218 0.86115003        nan        nan        nan\n",
      " 0.8605205  0.86214077 0.86260153        nan 0.86143475 0.84482353\n",
      "        nan        nan        nan 0.86024186 0.86104076 0.86172735\n",
      " 0.85689751        nan        nan        nan        nan        nan\n",
      " 0.85598145        nan        nan        nan        nan 0.85897855\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "{'colsample_bytree': 0.5082773464549667, 'learning_rate': 0.16088292571961926, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 448, 'subsample': 0.5555288772637191}\n",
      "Training Metrics:\n",
      "Accuracy: 0.8777958549348616\n",
      "Precision: 0.812604481450524\n",
      "Recall: 0.9820671903646054\n",
      "F1-Score: 0.8893350382788113\n",
      "ROC AUC Score: 0.8777958549348616\n",
      "Brier Score: 0.12220414506513848\n",
      "Test Metrics:\n",
      "Accuracy: 0.8040249749135913\n",
      "Precision: 0.8130189906798224\n",
      "Recall: 0.9806779661016949\n",
      "F1-Score: 0.8890128370542337\n",
      "ROC AUC Score: 0.5382727135050545\n",
      "Brier Score: 0.19597502508640874\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.1, 0.6),\n",
    "    'subsample': uniform(0.3, 0.9),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'colsample_bytree': uniform(0.5, 0.9),\n",
    "    'min_child_weight': randint(1, 6)\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier and RandomizedSearchCV objects\n",
    "xgb = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Predict the targets for the training and test data\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calculate evaluation metrics for training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "train_brier_score = brier_score_loss(y_train, y_train_pred)\n",
    "\n",
    "# Calculate evaluation metrics for test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_brier_score = brier_score_loss(y_test, y_test_pred)\n",
    "\n",
    "# Print the best model parameters\n",
    "print(\"Best Model Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Print the evaluation metrics for training data\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Accuracy:\", train_accuracy)\n",
    "print(\"Precision:\", train_precision)\n",
    "print(\"Recall:\", train_recall)\n",
    "print(\"F1-Score:\", train_f1)\n",
    "print(\"ROC AUC Score:\", train_roc_auc)\n",
    "print(\"Brier Score:\", train_brier_score)\n",
    "\n",
    "# Print the evaluation metrics for test data\n",
    "print(\"Test Metrics:\")\n",
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", test_precision)\n",
    "print(\"Recall:\", test_recall)\n",
    "print(\"F1-Score:\", test_f1)\n",
    "print(\"ROC AUC Score:\", test_roc_auc)\n",
    "print(\"Brier Score:\", test_brier_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a676fc9-05c9-495f-887f-8bca1fc26980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the best model and pipline for building the app \n",
    "import joblib\n",
    "\n",
    "# 'best_model'\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "#  'pipeline'\n",
    "joblib.dump(pipeline, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979212ca-541c-4095-a160-045cee92b038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
